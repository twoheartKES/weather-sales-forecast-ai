{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "130RmZu1A8wabq-bPOeWVWVFkLvxVC_IW",
      "authorship_tag": "ABX9TyMN72rPVJxPU0Q/lSlJcqVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twoheartKES/weather-sales-forecast-ai/blob/main/%5Cnotebooks\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1tycnW9_Fta",
        "outputId": "1da7d344-7523-4ba4-8a43-a0016eecb1be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: /content/drive/MyDrive/AIê¸°ìƒ-ì§ˆë³‘ë°ì´í„°/feature_dataset/2023ë…„ë„_ê¸°í›„_ì»¬ëŸ¼ì •ì˜_FE.csv\n",
            "2024ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: /content/drive/MyDrive/AIê¸°ìƒ-ì§ˆë³‘ë°ì´í„°/feature_dataset/2024ë…„ë„_ê¸°í›„_ì»¬ëŸ¼ì •ì˜_FE.csv\n",
            "2025ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: /content/drive/MyDrive/AIê¸°ìƒ-ì§ˆë³‘ë°ì´í„°/feature_dataset/2025ë…„ë„_ê¸°í›„_ì»¬ëŸ¼ì •ì˜_FE.csv\n",
            "ê²½ê³ : ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ df_combinedê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
            "df_combinedê°€ ë¹„ì–´ ìˆì–´ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ë° ëª¨ë¸ ì •ì˜ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœ€.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# ============================================================\n",
        "# 1. ì—°ë„ë³„ Feature Engineering ì™„ë£Œ ë°ì´í„° ë¡œë“œ\n",
        "#    - 2023, 2024, 2025ë…„ ë°ì´í„°ë¥¼ ëª¨ë‘ í•˜ë‚˜ë¡œ í•©ì¹¨\n",
        "# ============================================================\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/AIê¸°ìƒ-ì§ˆë³‘ë°ì´í„°/feature_dataset/'\n",
        "dfs_fe = {}\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "for year in years:\n",
        "    file_path = f\"{input_dir}{year}ë…„ë„_ê¸°í›„_ì»¬ëŸ¼ì •ì˜_FE.csv\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
        "        df['date'] = pd.to_datetime(df['date'])  # ë‚ ì§œ ì»¬ëŸ¼ì„ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜\n",
        "        dfs_fe[year] = df\n",
        "    except FileNotFoundError:\n",
        "        print(f\"{year}ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "# ì—°ë„ë³„ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ê²°í•©\n",
        "# dfs_fe ë”•ì…”ë„ˆë¦¬ì— ë°ì´í„°ê°€ ìˆëŠ” ì—°ë„ë§Œ ì„ íƒí•˜ì—¬ ê²°í•©\n",
        "if dfs_fe:\n",
        "    df_combined = pd.concat(\n",
        "        [dfs_fe[year] for year in years if year in dfs_fe],\n",
        "        ignore_index=True\n",
        "    )\n",
        "    print(f\"ëª¨ë“  ì—°ë„ ë°ì´í„° ê²°í•© ì™„ë£Œ. ì´ {len(df_combined)}í–‰\")\n",
        "elif not dfs_fe:\n",
        "    print(\"ê²½ê³ : ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ df_combinedê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    # df_combinedê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì´í›„ ì½”ë“œ ì‹¤í–‰ì„ ë§‰ê±°ë‚˜ ì ì ˆíˆ ì²˜ë¦¬í•´ì•¼ í•¨.\n",
        "    # ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ ë¹ˆ DataFrameì„ ìƒì„±í•˜ì—¬ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ì§€ë§Œ, ì‹¤ì œ ìƒí™©ì—ì„œëŠ” ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "    df_combined = pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. LSTM ì…ë ¥ìš© ì‹œê³„ì—´ ë°ì´í„° ìƒì„±\n",
        "#    - ì§€ì—­(region) + ì§ˆë³‘(disease_subtitle) ë‹¨ìœ„ë¡œ ì‹œê³„ì—´ êµ¬ì„±\n",
        "#    - ê³¼ê±° 14ì¼(window)ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "# ============================================================\n",
        "\n",
        "# df_combinedê°€ ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±\n",
        "if not df_combined.empty:\n",
        "\n",
        "    WINDOW_SIZE = 14  # í•˜ë£¨ ì˜ˆì¸¡ì„ ìœ„í•´ ê³¼ê±° 14ì¼ì„ ì‚¬ìš©\n",
        "    #ì˜ˆì‹œ:\n",
        "    #X[0] = [1ì¼~14ì¼ì˜ ê¸°ìƒ ë°ì´í„°] â†’ y[0] = 15ì¼ í™•ì§„ì ìˆ˜\n",
        "    #X[1] = [2ì¼~15ì¼ì˜ ê¸°ìƒ ë°ì´í„°] â†’ y[1] = 16ì¼ í™•ì§„ì ìˆ˜\n",
        "\n",
        "    # LSTM ì…ë ¥ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ë“¤\n",
        "    # (ì‹ë³„ì / ëª©í‘œê°’ / ì‹œê³„ì—´ì— ì§ì ‘ ì“°ì§€ ì•ŠëŠ” ì»¬ëŸ¼)\n",
        "    DROP_COLS_FOR_SEQUENCE = [\n",
        "        'date',\n",
        "        'region',\n",
        "        'disease_subtitle',\n",
        "        'ì§€ì ',\n",
        "        'ì§€ì ëª…',\n",
        "        'confirmed_cases'  # ì˜ˆì¸¡ ëŒ€ìƒì´ë¯€ë¡œ ì…ë ¥ì—ì„œëŠ” ì œê±°\n",
        "    ]\n",
        "\n",
        "    X_sequences = []  # LSTM ì…ë ¥ ë°ì´í„° (14ì¼ Ã— feature ìˆ˜)\n",
        "    y_targets = []    # ì˜ˆì¸¡ ëŒ€ìƒ (ë‹¤ìŒ ë‚  í™•ì§„ì ìˆ˜)\n",
        "\n",
        "    # ì§€ì—­ + ì§ˆë³‘ ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”\n",
        "    grouped = df_combined.groupby(['region', 'disease_subtitle'])\n",
        "\n",
        "    for (region, disease_subtitle), group_df in grouped:\n",
        "        # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ì‹œê³„ì—´ í•„ìˆ˜)\n",
        "        group_df = group_df.sort_values(by='date').reset_index(drop=True)\n",
        "\n",
        "        # ì…ë ¥ featureì™€ íƒ€ê¹ƒ ë¶„ë¦¬\n",
        "        features = group_df.drop(columns=DROP_COLS_FOR_SEQUENCE)\n",
        "        targets = group_df['confirmed_cases']\n",
        "\n",
        "        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ ì‹œê³„ì—´ ìƒì„±\n",
        "        for i in range(len(group_df) - WINDOW_SIZE):\n",
        "            # t-14 ~ t-1 ê¹Œì§€ì˜ ë°ì´í„°\n",
        "            X_seq = features.iloc[i : i + WINDOW_SIZE].values\n",
        "\n",
        "            # t ì‹œì ì˜ í™•ì§„ì ìˆ˜\n",
        "            y_target = targets.iloc[i + WINDOW_SIZE]\n",
        "\n",
        "            X_sequences.append(X_seq)\n",
        "            y_targets.append(y_target)\n",
        "\n",
        "    # numpy ë°°ì—´ë¡œ ë³€í™˜ (LSTM ì…ë ¥ í˜•ì‹)\n",
        "    X_sequences = np.array(X_sequences)  # (samples, timesteps, features)\n",
        "    y_targets = np.array(y_targets)      # (samples, )\n",
        "\n",
        "    # ============================================================\n",
        "    # 3. 2025ë…„ 12ì›” ì˜ˆì¸¡ìš© ë°ì´í„° ë¶„ë¦¬\n",
        "    #    - 12ì›” ë°ì´í„° â†’ í…ŒìŠ¤íŠ¸\n",
        "    #    - ê·¸ ì´ì „ ë°ì´í„° â†’ í•™ìŠµ\n",
        "    # ============================================================\n",
        "\n",
        "    start_date_dec2025 = pd.to_datetime('2025-12-01')\n",
        "    end_date_dec2025 = pd.to_datetime('2025-12-31')\n",
        "\n",
        "    all_target_dates = []\n",
        "\n",
        "    # ì§€ì—­-ì§ˆë³‘ë³„ë¡œ ê·¸ë£¹ ë‚˜ëˆ„ê¸°# ê° ì‹œê³„ì—´ ìƒ˜í”Œì´ ì–´ë–¤ ë‚ ì§œë¥¼ ì˜ˆì¸¡í•˜ëŠ”ì§€ ê¸°ë¡\n",
        "    grouped = df_combined.groupby(['region', 'disease_subtitle'])\n",
        "\n",
        "    for (_, _), group_df in grouped:\n",
        "        group_df = group_df.sort_values(by='date').reset_index(drop=True)\n",
        "        for i in range(len(group_df) - WINDOW_SIZE):\n",
        "            target_date = group_df['date'].iloc[i + WINDOW_SIZE]\n",
        "            all_target_dates.append(target_date)\n",
        "\n",
        "    all_target_dates = np.array(all_target_dates)\n",
        "\n",
        "    # 2025ë…„ 12ì›”ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œë§Œ True\n",
        "    dec2025_mask = (\n",
        "        (all_target_dates >= start_date_dec2025) &\n",
        "        (all_target_dates <= end_date_dec2025)\n",
        "    )\n",
        "\n",
        "    # í•™ìŠµ / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬\n",
        "    # 2025ë…„ 12ì›”ì„ ì˜ˆì¸¡í•˜ëŠ” ì‹œí€€ìŠ¤ = í…ŒìŠ¤íŠ¸\n",
        "\n",
        "    X_train_lstm = X_sequences[~dec2025_mask] # í…ŒìŠ¤íŠ¸ ì…ë ¥\n",
        "    y_train_lstm = y_targets[~dec2025_mask] # í›ˆë ¨ ì…ë ¥\n",
        "\n",
        "    X_test_dec2025 = X_sequences[dec2025_mask] # í…ŒìŠ¤íŠ¸ ì •ë‹µ\n",
        "    y_test_dec2025 = y_targets[dec2025_mask] # í›ˆë ¨ ì •ë‹µ\n",
        "\n",
        "\n",
        "    # ============================================================\n",
        "    # 4. LSTM ëª¨ë¸ ì •ì˜\n",
        "    # ============================================================\n",
        "\n",
        "    # LSTM ì…ë ¥ í˜•íƒœ í™•ì¸\n",
        "    # (íƒ€ì„ìŠ¤í… ìˆ˜, í”¼ì²˜ ìˆ˜)\n",
        "    input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
        "    print(f\"LSTM ì…ë ¥ í˜•íƒœ: {input_shape}\")\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # ê³¼ê±° 14ì¼ì˜ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ” LSTM ë ˆì´ì–´\n",
        "    model.add(\n",
        "        LSTM(\n",
        "            units=50,\n",
        "            activation='relu',\n",
        "            input_shape=input_shape\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # ë‹¤ìŒ ë‚  í™•ì§„ì ìˆ˜ 1ê°œ ê°’ì„ ì˜ˆì¸¡\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ MSE ì‚¬ìš©\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='mse'\n",
        "    )\n",
        "\n",
        "    print(\"\\nLSTM ëª¨ë¸ êµ¬ì¡° ìš”ì•½\")\n",
        "    model.summary()\n",
        "else:\n",
        "    print(\"df_combinedê°€ ë¹„ì–´ ìˆì–´ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ë° ëª¨ë¸ ì •ì˜ ë‹¨ê³„ë¥¼ ê±´ë„ˆëœ€.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4Y4_1D4r_xfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” LSTM ëª¨ë¸\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================================\n",
        "# 1. ì—°ë„ë³„ Feature Engineering ì™„ë£Œ ë°ì´í„° ë¡œë“œ\n",
        "# ============================================================\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/AIê¸°ìƒ-ì§ˆë³‘ë°ì´í„°/feature_dataset/'\n",
        "dfs_fe = {}\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "print(\"\\nğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
        "for year in years:\n",
        "    file_path = f\"{input_dir}{year}ë…„ë„_ê¸°í›„_ì»¬ëŸ¼ì •ì˜_FE.csv\"\n",
        "    try:\n",
        "        # ë©”ëª¨ë¦¬ ì ˆì•½: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì½ê¸° (ì˜µì…˜)\n",
        "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        dfs_fe[year] = df\n",
        "        print(f\"  âœ… {year}ë…„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  âŒ {year}ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ {year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "# ì—°ë„ë³„ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ê²°í•©\n",
        "df_combined = pd.concat(\n",
        "    [dfs_fe[2023], dfs_fe[2024], dfs_fe[2025]],\n",
        "    ignore_index=True\n",
        ")\n",
        "print(f\"âœ… ì „ì²´ ë°ì´í„°: {len(df_combined):,}í–‰\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. LSTM ì…ë ¥ìš© ì‹œê³„ì—´ ë°ì´í„° ìƒì„±\n",
        "# ============================================================\n",
        "\n",
        "WINDOW_SIZE = 14  # ê³¼ê±° 14ì¼ì„ ì‚¬ìš©\n",
        "\n",
        "# LSTM ì…ë ¥ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ë“¤\n",
        "DROP_COLS_FOR_SEQUENCE = [\n",
        "    'date',\n",
        "    'region',\n",
        "    'disease_subtitle',\n",
        "    'ì§€ì ',\n",
        "    'ì§€ì ëª…',\n",
        "    'confirmed_cases'  # ì˜ˆì¸¡ ëŒ€ìƒ\n",
        "]\n",
        "\n",
        "X_sequences = []\n",
        "y_targets = []\n",
        "all_target_dates = []\n",
        "\n",
        "print(\"\\nğŸ”„ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì¤‘...\")\n",
        "grouped = df_combined.groupby(['region', 'disease_subtitle'])\n",
        "\n",
        "for idx, ((region, disease_subtitle), group_df) in enumerate(grouped, 1):\n",
        "    # ì§„í–‰ìƒí™© í‘œì‹œ\n",
        "    if idx % 10 == 0:\n",
        "        print(f\"  ì§„í–‰ì¤‘... {idx}/{len(grouped)}\")\n",
        "\n",
        "    group_df = group_df.sort_values(by='date').reset_index(drop=True)\n",
        "\n",
        "    # ì…ë ¥ featureì™€ íƒ€ê¹ƒ ë¶„ë¦¬\n",
        "    features = group_df.drop(columns=DROP_COLS_FOR_SEQUENCE)\n",
        "    targets = group_df['confirmed_cases']\n",
        "\n",
        "    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±\n",
        "    for i in range(len(group_df) - WINDOW_SIZE):\n",
        "        X_seq = features.iloc[i : i + WINDOW_SIZE].values\n",
        "        y_target = targets.iloc[i + WINDOW_SIZE]\n",
        "        target_date = group_df['date'].iloc[i + WINDOW_SIZE]\n",
        "\n",
        "        X_sequences.append(X_seq)\n",
        "        y_targets.append(y_target)\n",
        "        all_target_dates.append(target_date)\n",
        "\n",
        "print(f\"âœ… ì´ {len(X_sequences):,}ê°œ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
        "\n",
        "# numpy ë°°ì—´ë¡œ ë³€í™˜ + ë©”ëª¨ë¦¬ ìµœì í™” (float32 ì‚¬ìš©)\n",
        "print(\"\\nğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™” ì¤‘...\")\n",
        "X_sequences = np.array(X_sequences, dtype='float32')  # float64 â†’ float32\n",
        "y_targets = np.array(y_targets, dtype='float32')\n",
        "all_target_dates = np.array(all_target_dates)\n",
        "\n",
        "print(f\"  X_sequences: {X_sequences.shape}, {X_sequences.nbytes/(1024**2):.1f} MB\")\n",
        "print(f\"  y_targets: {y_targets.shape}, {y_targets.nbytes/(1024**2):.1f} MB\")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬: ì‚¬ìš© ì•ˆ í•˜ëŠ” í° ë³€ìˆ˜ ì‚­ì œ\n",
        "del df_combined, dfs_fe, grouped\n",
        "gc.collect()\n",
        "print(\"âœ… ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì‚­ì œ ì™„ë£Œ\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. 2025ë…„ 12ì›” ì˜ˆì¸¡ìš© ë°ì´í„° ë¶„ë¦¬\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“Š í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ ì¤‘...\")\n",
        "start_date_dec2025 = pd.to_datetime('2025-12-01')\n",
        "end_date_dec2025 = pd.to_datetime('2025-12-31')\n",
        "\n",
        "# 2025ë…„ 12ì›” ë§ˆìŠ¤í¬\n",
        "dec2025_mask = (\n",
        "    (all_target_dates >= start_date_dec2025) &\n",
        "    (all_target_dates <= end_date_dec2025)\n",
        ")\n",
        "\n",
        "# ë°ì´í„° ë¶„ë¦¬\n",
        "X_train_lstm = X_sequences[~dec2025_mask]\n",
        "y_train_lstm = y_targets[~dec2025_mask]\n",
        "X_test_dec2025 = X_sequences[dec2025_mask]\n",
        "y_test_dec2025 = y_targets[dec2025_mask]\n",
        "\n",
        "print(f\"  í›ˆë ¨ ë°ì´í„°: {X_train_lstm.shape[0]:,}ê°œ\")\n",
        "print(f\"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_dec2025.shape[0]:,}ê°œ\")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "del X_sequences, y_targets, all_target_dates\n",
        "gc.collect()\n",
        "\n",
        "# ============================================================\n",
        "# 4. ê²½ëŸ‰í™”ëœ LSTM ëª¨ë¸ ì •ì˜\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ—ï¸ ëª¨ë¸ êµ¬ì„± ì¤‘...\")\n",
        "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
        "print(f\"  ì…ë ¥ í˜•íƒœ: {input_shape}\")\n",
        "\n",
        "# ê²½ëŸ‰ ëª¨ë¸ (units 50 â†’ 32)\n",
        "model = Sequential([\n",
        "    LSTM(\n",
        "        units=32,              # 50 â†’ 32 (ë©”ëª¨ë¦¬ 40% ì ˆì•½)\n",
        "        activation='relu',\n",
        "        input_shape=input_shape,\n",
        "        recurrent_dropout=0.1  # ê³¼ì í•© ë°©ì§€\n",
        "    ),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae']  # ì¶”ê°€ ì§€í‘œ\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“‹ ëª¨ë¸ êµ¬ì¡°:\")\n",
        "model.summary()\n",
        "\n",
        "# ============================================================\n",
        "# 5. ëª¨ë¸ í•™ìŠµ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ì¡°ê¸° ì¢…ë£Œ ì½œë°±\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,              # 5 ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# í•™ìŠµ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •)\n",
        "history = model.fit(\n",
        "    X_train_lstm,\n",
        "    y_train_lstm,\n",
        "    epochs=50,               # ìµœëŒ€ 50ë²ˆ (ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥)\n",
        "    batch_size=128,          # í° ë°°ì¹˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "    validation_split=0.15,   # ê²€ì¦ ë°ì´í„° 15%\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n",
        "print(f\"ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ë¶„\")\n",
        "print(f\"ì‹¤ì œ ì—í¬í¬: {len(history.history['loss'])}ë²ˆ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================================\n",
        "# 6. ì˜ˆì¸¡ ë° í‰ê°€\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ”® ì˜ˆì¸¡ ì¤‘...\")\n",
        "predictions = model.predict(X_test_dec2025, batch_size=256, verbose=0)\n",
        "predictions = np.maximum(predictions, 0)  # ìŒìˆ˜ ì œê±°\n",
        "\n",
        "# í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "mse = mean_squared_error(y_test_dec2025, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_dec2025, predictions)\n",
        "r2 = r2_score(y_test_dec2025, predictions)\n",
        "\n",
        "print(\"\\nğŸ“Š ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"MSE  (í‰ê·  ì œê³± ì˜¤ì°¨)    : {mse:.2f}\")\n",
        "print(f\"RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)  : {rmse:.2f}\")\n",
        "print(f\"MAE  (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)    : {mae:.2f}\")\n",
        "print(f\"RÂ²   (ê²°ì • ê³„ìˆ˜)         : {r2:.4f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# ì˜ˆì¸¡ ìƒ˜í”Œ ì¶œë ¥\n",
        "print(\"\\nğŸ¯ ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\")\n",
        "print(f\"{'ì‹¤ì œê°’':>10} | {'ì˜ˆì¸¡ê°’':>10} | {'ì˜¤ì°¨':>10}\")\n",
        "print(\"-\" * 36)\n",
        "for i in range(min(10, len(y_test_dec2025))):\n",
        "    actual = y_test_dec2025[i]\n",
        "    pred = predictions[i][0]\n",
        "    error = actual - pred\n",
        "    print(f\"{actual:10.1f} | {pred:10.1f} | {error:+10.1f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“ˆ í•™ìŠµ ê³¡ì„  ìƒì„± ì¤‘...\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss ê·¸ë˜í”„\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('MSE Loss', fontsize=12)\n",
        "plt.title('í•™ìŠµ ê³¡ì„  (Loss)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# MAE ê·¸ë˜í”„\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('MAE', fontsize=12)\n",
        "plt.title('í•™ìŠµ ê³¡ì„  (MAE)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… ì‹œê°í™” ì™„ë£Œ!\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. ëª¨ë¸ ì €ì¥ (ì„ íƒ)\n",
        "# ============================================================\n",
        "\n",
        "# Google Driveì— ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ ì£¼ì„ ì œê±°\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# model.save('/content/drive/MyDrive/lstm_model_optimized.h5')\n",
        "# print(\"\\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "ICalH0Yd_x0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YIQkWAFC_5nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸš€ ë©”ëª¨ë¦¬ ìµœì í™” LSTM ëª¨ë¸\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================================\n",
        "# 1. ì—°ë„ë³„ Feature Engineering ì™„ë£Œ ë°ì´í„° ë¡œë“œ\n",
        "# ============================================================\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/AIê¸°ìƒ-ì§ˆë³‘ë°ì´í„°/feature_dataset/'\n",
        "dfs_fe = {}\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "print(\"\\nğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
        "for year in years:\n",
        "    file_path = f\"{input_dir}{year}ë…„ë„_ê¸°í›„_ì»¬ëŸ¼ì •ì˜_FE.csv\"\n",
        "    try:\n",
        "        # ë©”ëª¨ë¦¬ ì ˆì•½: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì½ê¸° (ì˜µì…˜)\n",
        "        df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
        "        df['date'] = pd.to_datetime(df['date'])\n",
        "        dfs_fe[year] = df\n",
        "        print(f\"  âœ… {year}ë…„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  âŒ {year}ë…„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ {year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "\n",
        "# ì—°ë„ë³„ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ ê²°í•©\n",
        "df_combined = pd.concat(\n",
        "    [dfs_fe[2023], dfs_fe[2024], dfs_fe[2025]],\n",
        "    ignore_index=True\n",
        ")\n",
        "print(f\"âœ… ì „ì²´ ë°ì´í„°: {len(df_combined):,}í–‰\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. LSTM ì…ë ¥ìš© ì‹œê³„ì—´ ë°ì´í„° ìƒì„±\n",
        "# ============================================================\n",
        "\n",
        "WINDOW_SIZE = 14  # ê³¼ê±° 14ì¼ì„ ì‚¬ìš©\n",
        "\n",
        "# LSTM ì…ë ¥ì—ì„œ ì œì™¸í•  ì»¬ëŸ¼ë“¤\n",
        "DROP_COLS_FOR_SEQUENCE = [\n",
        "    'date',\n",
        "    'region',\n",
        "    'disease_subtitle',\n",
        "    'ì§€ì ',\n",
        "    'ì§€ì ëª…',\n",
        "    'confirmed_cases'  # ì˜ˆì¸¡ ëŒ€ìƒ\n",
        "]\n",
        "\n",
        "X_sequences = []\n",
        "y_targets = []\n",
        "all_target_dates = []\n",
        "all_regions = []  # ì§€ì—­ ì •ë³´ ì €ì¥\n",
        "all_diseases = []  # ì§ˆë³‘ ì •ë³´ ì €ì¥\n",
        "\n",
        "print(\"\\nğŸ”„ ì‹œê³„ì—´ ë°ì´í„° ìƒì„± ì¤‘...\")\n",
        "grouped = df_combined.groupby(['region', 'disease_subtitle'])\n",
        "\n",
        "for idx, ((region, disease_subtitle), group_df) in enumerate(grouped, 1):\n",
        "    # ì§„í–‰ìƒí™© í‘œì‹œ\n",
        "    if idx % 10 == 0:\n",
        "        print(f\"  ì§„í–‰ì¤‘... {idx}/{len(grouped)}\")\n",
        "\n",
        "    group_df = group_df.sort_values(by='date').reset_index(drop=True)\n",
        "\n",
        "    # ì…ë ¥ featureì™€ íƒ€ê¹ƒ ë¶„ë¦¬\n",
        "    features = group_df.drop(columns=DROP_COLS_FOR_SEQUENCE)\n",
        "    targets = group_df['confirmed_cases']\n",
        "\n",
        "    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±\n",
        "    for i in range(len(group_df) - WINDOW_SIZE):\n",
        "        X_seq = features.iloc[i : i + WINDOW_SIZE].values\n",
        "        y_target = targets.iloc[i + WINDOW_SIZE]\n",
        "        target_date = group_df['date'].iloc[i + WINDOW_SIZE]\n",
        "\n",
        "        X_sequences.append(X_seq)\n",
        "        y_targets.append(y_target)\n",
        "        all_target_dates.append(target_date)\n",
        "        all_regions.append(region)  # ì§€ì—­ ì €ì¥\n",
        "        all_diseases.append(disease_subtitle)  # ì§ˆë³‘ ì €ì¥\n",
        "\n",
        "print(f\"âœ… ì´ {len(X_sequences):,}ê°œ ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ\")\n",
        "\n",
        "# numpy ë°°ì—´ë¡œ ë³€í™˜ + ë©”ëª¨ë¦¬ ìµœì í™” (float32 ì‚¬ìš©)\n",
        "print(\"\\nğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™” ì¤‘...\")\n",
        "X_sequences = np.array(X_sequences, dtype='float32')  # float64 â†’ float32\n",
        "y_targets = np.array(y_targets, dtype='float32')\n",
        "all_target_dates = np.array(all_target_dates)\n",
        "\n",
        "print(f\"  X_sequences: {X_sequences.shape}, {X_sequences.nbytes/(1024**2):.1f} MB\")\n",
        "print(f\"  y_targets: {y_targets.shape}, {y_targets.nbytes/(1024**2):.1f} MB\")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬: ì‚¬ìš© ì•ˆ í•˜ëŠ” í° ë³€ìˆ˜ ì‚­ì œ\n",
        "del df_combined, dfs_fe, grouped\n",
        "gc.collect()\n",
        "print(\"âœ… ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì‚­ì œ ì™„ë£Œ\")\n",
        "\n",
        "# ============================================================\n",
        "# 3. 2025ë…„ 12ì›” ì˜ˆì¸¡ìš© ë°ì´í„° ë¶„ë¦¬\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“Š í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ ì¤‘...\")\n",
        "start_date_dec2025 = pd.to_datetime('2025-12-01')\n",
        "end_date_dec2025 = pd.to_datetime('2025-12-31')\n",
        "\n",
        "# 2025ë…„ 12ì›” ë§ˆìŠ¤í¬\n",
        "dec2025_mask = (\n",
        "    (all_target_dates >= start_date_dec2025) &\n",
        "    (all_target_dates <= end_date_dec2025)\n",
        ")\n",
        "\n",
        "# ë°ì´í„° ë¶„ë¦¬\n",
        "X_train_lstm = X_sequences[~dec2025_mask]\n",
        "y_train_lstm = y_targets[~dec2025_mask]\n",
        "X_test_dec2025 = X_sequences[dec2025_mask]\n",
        "y_test_dec2025 = y_targets[dec2025_mask]\n",
        "\n",
        "print(f\"  í›ˆë ¨ ë°ì´í„°: {X_train_lstm.shape[0]:,}ê°œ\")\n",
        "print(f\"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test_dec2025.shape[0]:,}ê°œ\")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ ì •ë¦¬\n",
        "del X_sequences, y_targets, all_target_dates\n",
        "gc.collect()\n",
        "\n",
        "# ============================================================\n",
        "# 4. ê²½ëŸ‰í™”ëœ LSTM ëª¨ë¸ ì •ì˜\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ—ï¸ ëª¨ë¸ êµ¬ì„± ì¤‘...\")\n",
        "input_shape = (X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
        "print(f\"  ì…ë ¥ í˜•íƒœ: {input_shape}\")\n",
        "\n",
        "# ê²½ëŸ‰ ëª¨ë¸ (units 50 â†’ 32)\n",
        "model = Sequential([\n",
        "    LSTM(\n",
        "        units=32,              # 50 â†’ 32 (ë©”ëª¨ë¦¬ 40% ì ˆì•½)\n",
        "        activation='relu',\n",
        "        input_shape=input_shape,\n",
        "        recurrent_dropout=0.1  # ê³¼ì í•© ë°©ì§€\n",
        "    ),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='mse',\n",
        "    metrics=['mae']  # ì¶”ê°€ ì§€í‘œ\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“‹ ëª¨ë¸ êµ¬ì¡°:\")\n",
        "model.summary()\n",
        "\n",
        "# ============================================================\n",
        "# 5. ëª¨ë¸ í•™ìŠµ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ì¡°ê¸° ì¢…ë£Œ ì½œë°±\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,              # 5 ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# í•™ìŠµ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ì •)\n",
        "history = model.fit(\n",
        "    X_train_lstm,\n",
        "    y_train_lstm,\n",
        "    epochs=50,               # ìµœëŒ€ 50ë²ˆ (ì¡°ê¸° ì¢…ë£Œ ê°€ëŠ¥)\n",
        "    batch_size=128,          # í° ë°°ì¹˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )\n",
        "    validation_split=0.15,   # ê²€ì¦ ë°ì´í„° 15%\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n",
        "print(f\"ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ë¶„\")\n",
        "print(f\"ì‹¤ì œ ì—í¬í¬: {len(history.history['loss'])}ë²ˆ\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================================\n",
        "# 6. ì˜ˆì¸¡ ë° í‰ê°€\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ”® ì˜ˆì¸¡ ì¤‘...\")\n",
        "predictions = model.predict(X_test_dec2025, batch_size=256, verbose=0)\n",
        "predictions = np.maximum(predictions, 0)  # ìŒìˆ˜ ì œê±°\n",
        "\n",
        "# í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "mse = mean_squared_error(y_test_dec2025, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_dec2025, predictions)\n",
        "r2 = r2_score(y_test_dec2025, predictions)\n",
        "\n",
        "print(\"\\nğŸ“Š ì„±ëŠ¥ í‰ê°€ ê²°ê³¼:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"MSE  (í‰ê·  ì œê³± ì˜¤ì°¨)    : {mse:.2f}\")\n",
        "print(f\"RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)  : {rmse:.2f}\")\n",
        "print(f\"MAE  (í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)    : {mae:.2f}\")\n",
        "print(f\"RÂ²   (ê²°ì • ê³„ìˆ˜)         : {r2:.4f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# ì˜ˆì¸¡ ìƒ˜í”Œ ì¶œë ¥\n",
        "print(\"\\nğŸ¯ ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\")\n",
        "print(f\"{'ì‹¤ì œê°’':>10} | {'ì˜ˆì¸¡ê°’':>10} | {'ì˜¤ì°¨':>10}\")\n",
        "print(\"-\" * 36)\n",
        "for i in range(min(10, len(y_test_dec2025))):\n",
        "    actual = y_test_dec2025[i]\n",
        "    pred = predictions[i][0]\n",
        "    error = actual - pred\n",
        "    print(f\"{actual:10.1f} | {pred:10.1f} | {error:+10.1f}\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. í•™ìŠµ ê³¡ì„  ì‹œê°í™”\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“ˆ í•™ìŠµ ê³¡ì„  ìƒì„± ì¤‘...\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss ê·¸ë˜í”„\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('MSE Loss', fontsize=12)\n",
        "plt.title('í•™ìŠµ ê³¡ì„  (Loss)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# MAE ê·¸ë˜í”„\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
        "plt.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
        "plt.xlabel('Epoch', fontsize=12)\n",
        "plt.ylabel('MAE', fontsize=12)\n",
        "plt.title('í•™ìŠµ ê³¡ì„  (MAE)', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… ì‹œê°í™” ì™„ë£Œ!\")\n",
        "\n",
        "# ============================================================\n",
        "# 8. ëª¨ë¸ ì €ì¥ (ì„ íƒ)\n",
        "# ============================================================\n",
        "\n",
        "# Google Driveì— ì €ì¥í•˜ê³  ì‹¶ë‹¤ë©´ ì£¼ì„ ì œê±°\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "model.save('/content/drive/MyDrive/lstm_model_optimized.h5')\n",
        "print(\"\\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "pGuWbIoI_5zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XdEfMHgMAGdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib as mpl\n",
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "# ============================================================\n",
        "expected_nanum_font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "\n",
        "try:\n",
        "    if os.path.exists(expected_nanum_font_path):\n",
        "        fm.fontManager.addfont(expected_nanum_font_path)\n",
        "        prop = fm.FontProperties(fname=expected_nanum_font_path)\n",
        "        font_name = prop.get_name()\n",
        "        mpl.rc('font', family=font_name)\n",
        "        print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì •: {font_name}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"NanumGothic í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {expected_nanum_font_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}\")\n",
        "    print(\"ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
        "\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ“Š 2025ë…„ 12ì›” í™•ì§„ì ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ë¶„ì„\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ============================================================\n",
        "# 1. ì˜ˆì¸¡ ê²°ê³¼ DataFrame ìƒì„± (ì´ë¯¸ ìˆë‹¤ë©´ ê±´ë„ˆë›°ê¸°)\n",
        "# ============================================================\n",
        "\n",
        "if 'results_df' not in globals():\n",
        "    print(\"\\nâš ï¸ results_dfê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € LSTM ëª¨ë¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
        "    # results_df ìƒì„± ì½”ë“œ (LSTM ì½”ë“œì—ì„œ ê°€ì ¸ì˜´)\n",
        "    results_df = pd.DataFrame({\n",
        "        'date': test_dates,\n",
        "        'region': test_regions,\n",
        "        'disease': test_diseases,\n",
        "        'actual': y_test_dec2025,\n",
        "        'prediction': predictions.flatten(),\n",
        "        'error': y_test_dec2025 - predictions.flatten(),\n",
        "        'abs_error': np.abs(y_test_dec2025 - predictions.flatten())\n",
        "    })\n",
        "    results_df = results_df.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nâœ… ì´ {len(results_df):,}ê°œ ì˜ˆì¸¡ ê²°ê³¼\")\n",
        "\n",
        "# ============================================================\n",
        "# 2. ë‚ ì§œë³„ ì „ì²´ í™•ì§„ì ì¶”ì´\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“… ë‚ ì§œë³„ í™•ì§„ì ìˆ˜ ë¶„ì„...\")\n",
        "\n",
        "# ë‚ ì§œë³„ ì´ í™•ì§„ì (ëª¨ë“  ì§€ì—­/ì§ˆë³‘ í•©ì‚°)\n",
        "daily_total = results_df.groupby('date').agg({\n",
        "    'actual': 'sum',\n",
        "    'prediction': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "print(\"\\n[ë‚ ì§œë³„ ì´ í™•ì§„ì ìˆ˜ (ìƒìœ„ 10ì¼)]\")\n",
        "print(daily_total.head(10).to_string(index=False))\n",
        "\n",
        "# ============================================================\n",
        "# 3. ì§€ì—­ë³„ 12ì›” ì´ í™•ì§„ì\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ—ºï¸ ì§€ì—­ë³„ 12ì›” ì´ í™•ì§„ì...\")\n",
        "\n",
        "region_total = results_df.groupby('region').agg({\n",
        "    'actual': 'sum',\n",
        "    'prediction': 'sum',\n",
        "    'abs_error': 'mean'\n",
        "}).round(1)\n",
        "region_total.columns = ['ì‹¤ì œ_ì´í•©', 'ì˜ˆì¸¡_ì´í•©', 'í‰ê· _ì ˆëŒ€ì˜¤ì°¨']\n",
        "region_total = region_total.sort_values('ì‹¤ì œ_ì´í•©', ascending=False)\n",
        "\n",
        "print(\"\\n[ì§€ì—­ë³„ 12ì›” ì´ í™•ì§„ì]\")\n",
        "print(region_total)\n",
        "\n",
        "# ============================================================\n",
        "# 4. ì§ˆë³‘ë³„ 12ì›” ì´ í™•ì§„ì\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ¦  ì§ˆë³‘ë³„ 12ì›” ì´ í™•ì§„ì...\")\n",
        "\n",
        "disease_total = results_df.groupby('disease').agg({\n",
        "    'actual': 'sum',\n",
        "    'prediction': 'sum',\n",
        "    'abs_error': 'mean'\n",
        "}).round(1)\n",
        "disease_total.columns = ['ì‹¤ì œ_ì´í•©', 'ì˜ˆì¸¡_ì´í•©', 'í‰ê· _ì ˆëŒ€ì˜¤ì°¨']\n",
        "disease_total = disease_total.sort_values('ì‹¤ì œ_ì´í•©', ascending=False)\n",
        "\n",
        "print(\"\\n[ì§ˆë³‘ë³„ 12ì›” ì´ í™•ì§„ì]\")\n",
        "print(disease_total)\n",
        "\n",
        "# ============================================================\n",
        "# 5. ì§€ì—­ Ã— ì§ˆë³‘ ì¡°í•©ë³„ ë¶„ì„\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ” ì§€ì—­-ì§ˆë³‘ ì¡°í•©ë³„ ë¶„ì„...\")\n",
        "\n",
        "region_disease = results_df.groupby(['region', 'disease']).agg({\n",
        "    'actual': 'sum',\n",
        "    'prediction': 'sum',\n",
        "    'abs_error': 'mean'\n",
        "}).round(1)\n",
        "region_disease.columns = ['ì‹¤ì œ_ì´í•©', 'ì˜ˆì¸¡_ì´í•©', 'í‰ê· _ì ˆëŒ€ì˜¤ì°¨']\n",
        "region_disease = region_disease.sort_values('ì‹¤ì œ_ì´í•©', ascending=False)\n",
        "\n",
        "print(\"\\n[ì§€ì—­-ì§ˆë³‘ ì¡°í•© TOP 15]\")\n",
        "print(region_disease.head(15))\n",
        "\n",
        "# ============================================================\n",
        "# 6. ìƒì„¸ ì‹œê°í™”\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...\")\n",
        "\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "\n",
        "# 6-1. ë‚ ì§œë³„ ì´ í™•ì§„ì ì¶”ì´\n",
        "ax1 = plt.subplot(3, 3, 1)\n",
        "ax1.plot(daily_total['date'], daily_total['actual'],\n",
        "         marker='o', linewidth=2, label='ì‹¤ì œ', color='blue')\n",
        "ax1.plot(daily_total['date'], daily_total['prediction'],\n",
        "         marker='s', linewidth=2, label='ì˜ˆì¸¡', color='red', alpha=0.7)\n",
        "ax1.set_xlabel('ë‚ ì§œ', fontsize=11)\n",
        "ax1.set_ylabel('í™•ì§„ì ìˆ˜', fontsize=11)\n",
        "ax1.set_title('ë‚ ì§œë³„ ì´ í™•ì§„ì ì¶”ì´ (12ì›”)', fontsize=13, fontweight='bold')\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 6-2. ì§€ì—­ë³„ ì´ í™•ì§„ì (ì‹¤ì œ vs ì˜ˆì¸¡)\n",
        "ax2 = plt.subplot(3, 3, 2)\n",
        "x_pos = np.arange(len(region_total))\n",
        "width = 0.35\n",
        "ax2.bar(x_pos - width/2, region_total['ì‹¤ì œ_ì´í•©'], width,\n",
        "        label='ì‹¤ì œ', color='skyblue', alpha=0.8)\n",
        "ax2.bar(x_pos + width/2, region_total['ì˜ˆì¸¡_ì´í•©'], width,\n",
        "        label='ì˜ˆì¸¡', color='salmon', alpha=0.8)\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(region_total.index, rotation=45, ha='right')\n",
        "ax2.set_ylabel('í™•ì§„ì ìˆ˜', fontsize=11)\n",
        "ax2.set_title('ì§€ì—­ë³„ 12ì›” ì´ í™•ì§„ì', fontsize=13, fontweight='bold')\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 6-3. ì§ˆë³‘ë³„ ì´ í™•ì§„ì (ì‹¤ì œ vs ì˜ˆì¸¡)\n",
        "ax3 = plt.subplot(3, 3, 3)\n",
        "x_pos = np.arange(len(disease_total))\n",
        "ax3.bar(x_pos - width/2, disease_total['ì‹¤ì œ_ì´í•©'], width,\n",
        "        label='ì‹¤ì œ', color='lightgreen', alpha=0.8)\n",
        "ax3.bar(x_pos + width/2, disease_total['ì˜ˆì¸¡_ì´í•©'], width,\n",
        "        label='ì˜ˆì¸¡', color='orange', alpha=0.8)\n",
        "ax3.set_xticks(x_pos)\n",
        "ax3.set_xticklabels(disease_total.index, rotation=45, ha='right')\n",
        "ax3.set_ylabel('í™•ì§„ì ìˆ˜', fontsize=11)\n",
        "ax3.set_title('ì§ˆë³‘ë³„ 12ì›” ì´ í™•ì§„ì', fontsize=13, fontweight='bold')\n",
        "ax3.legend(fontsize=10)\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 6-4. ì§€ì—­ë³„ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨\n",
        "ax4 = plt.subplot(3, 3, 4)\n",
        "ax4.barh(region_total.index, region_total['í‰ê· _ì ˆëŒ€ì˜¤ì°¨'], color='coral')\n",
        "ax4.set_xlabel('í‰ê·  ì ˆëŒ€ ì˜¤ì°¨', fontsize=11)\n",
        "ax4.set_title('ì§€ì—­ë³„ ì˜ˆì¸¡ ì˜¤ì°¨', fontsize=13, fontweight='bold')\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 6-5. ì§ˆë³‘ë³„ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨\n",
        "ax5 = plt.subplot(3, 3, 5)\n",
        "ax5.barh(disease_total.index, disease_total['í‰ê· _ì ˆëŒ€ì˜¤ì°¨'], color='mediumpurple')\n",
        "ax5.set_xlabel('í‰ê·  ì ˆëŒ€ ì˜¤ì°¨', fontsize=11)\n",
        "ax5.set_title('ì§ˆë³‘ë³„ ì˜ˆì¸¡ ì˜¤ì°¨', fontsize=13, fontweight='bold')\n",
        "ax5.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 6-6. ì „ì²´ ì‹¤ì œ vs ì˜ˆì¸¡ ì‚°ì ë„\n",
        "ax6 = plt.subplot(3, 3, 6)\n",
        "ax6.scatter(results_df['actual'], results_df['prediction'],\n",
        "           alpha=0.5, s=30, color='steelblue')\n",
        "max_val = max(results_df['actual'].max(), results_df['prediction'].max())\n",
        "ax6.plot([0, max_val], [0, max_val], 'r--', lw=2, label='ì™„ë²½í•œ ì˜ˆì¸¡')\n",
        "ax6.set_xlabel('ì‹¤ì œ í™•ì§„ì ìˆ˜', fontsize=11)\n",
        "ax6.set_ylabel('ì˜ˆì¸¡ í™•ì§„ì ìˆ˜', fontsize=11)\n",
        "ax6.set_title('ì‹¤ì œ vs ì˜ˆì¸¡ (ì „ì²´)', fontsize=13, fontweight='bold')\n",
        "ax6.legend(fontsize=10)\n",
        "ax6.grid(True, alpha=0.3)\n",
        "\n",
        "# 6-7. ì˜¤ì°¨ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨\n",
        "ax7 = plt.subplot(3, 3, 7)\n",
        "ax7.hist(results_df['error'], bins=30, alpha=0.7,\n",
        "         color='teal', edgecolor='black')\n",
        "ax7.axvline(x=0, color='r', linestyle='--', linewidth=2, label='ì˜¤ì°¨ 0')\n",
        "ax7.set_xlabel('ì˜¤ì°¨ (ì‹¤ì œ - ì˜ˆì¸¡)', fontsize=11)\n",
        "ax7.set_ylabel('ë¹ˆë„', fontsize=11)\n",
        "ax7.set_title('ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„í¬', fontsize=13, fontweight='bold')\n",
        "ax7.legend(fontsize=10)\n",
        "ax7.grid(True, alpha=0.3)\n",
        "\n",
        "# 6-8. ì§€ì—­-ì§ˆë³‘ íˆíŠ¸ë§µ (ì‹¤ì œ í™•ì§„ì)\n",
        "ax8 = plt.subplot(3, 3, 8)\n",
        "pivot_actual = results_df.pivot_table(\n",
        "    values='actual',\n",
        "    index='disease',\n",
        "    columns='region',\n",
        "    aggfunc='sum'\n",
        ").fillna(0)\n",
        "sns.heatmap(pivot_actual, annot=True, fmt='.0f',\n",
        "            cmap='YlOrRd', ax=ax8, cbar_kws={'label': 'í™•ì§„ì ìˆ˜'})\n",
        "ax8.set_title('ì§€ì—­-ì§ˆë³‘ë³„ ì‹¤ì œ í™•ì§„ì (íˆíŠ¸ë§µ)', fontsize=13, fontweight='bold')\n",
        "\n",
        "# 6-9. ì§€ì—­-ì§ˆë³‘ íˆíŠ¸ë§µ (ì˜ˆì¸¡ í™•ì§„ì)\n",
        "ax9 = plt.subplot(3, 3, 9)\n",
        "pivot_pred = results_df.pivot_table(\n",
        "    values='prediction',\n",
        "    index='disease',\n",
        "    columns='region',\n",
        "    aggfunc='sum'\n",
        ").fillna(0)\n",
        "sns.heatmap(pivot_pred, annot=True, fmt='.0f',\n",
        "            cmap='YlGnBu', ax=ax9, cbar_kws={'label': 'í™•ì§„ì ìˆ˜'})\n",
        "ax9.set_title('ì§€ì—­-ì§ˆë³‘ë³„ ì˜ˆì¸¡ í™•ì§„ì (íˆíŠ¸ë§µ)', fontsize=13, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ… ì‹œê°í™” ì™„ë£Œ!\")\n",
        "\n",
        "# ============================================================\n",
        "# 7. íŠ¹ì • ë‚ ì§œì˜ ìƒì„¸ ì •ë³´\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“… íŠ¹ì • ë‚ ì§œë³„ ìƒì„¸ ì •ë³´...\")\n",
        "\n",
        "# 12ì›” 1ì¼, 15ì¼, 31ì¼ì˜ ìƒì„¸ ì •ë³´\n",
        "sample_dates = ['2025-12-01', '2025-12-15', '2025-12-31']\n",
        "\n",
        "for date_str in sample_dates:\n",
        "    target_date = pd.to_datetime(date_str)\n",
        "    day_data = results_df[results_df['date'] == target_date]\n",
        "\n",
        "    if len(day_data) > 0:\n",
        "        print(f\"\\n[{date_str} ìƒì„¸ ì •ë³´]\")\n",
        "        print(f\"ì´ í™•ì§„ì (ì‹¤ì œ): {day_data['actual'].sum():.0f}ëª…\")\n",
        "        print(f\"ì´ í™•ì§„ì (ì˜ˆì¸¡): {day_data['prediction'].sum():.0f}ëª…\")\n",
        "        print(f\"ì§€ì—­-ì§ˆë³‘ë³„ TOP 5:\")\n",
        "        top5 = day_data.nlargest(5, 'actual')[['region', 'disease', 'actual', 'prediction']]\n",
        "        print(top5.to_string(index=False))\n",
        "\n",
        "# ============================================================\n",
        "# 8. ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ì€/ë‚®ì€ ì¼€ì´ìŠ¤\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ¯ ì˜ˆì¸¡ ì •í™•ë„ ë¶„ì„...\")\n",
        "\n",
        "# ê°€ì¥ ì •í™•í•œ ì˜ˆì¸¡ TOP 10\n",
        "print(\"\\n[ê°€ì¥ ì •í™•í•œ ì˜ˆì¸¡ TOP 10]\")\n",
        "best_predictions = results_df.nsmallest(10, 'abs_error')[\n",
        "    ['date', 'region', 'disease', 'actual', 'prediction', 'abs_error']\n",
        "]\n",
        "print(best_predictions.to_string(index=False))\n",
        "\n",
        "# ê°€ì¥ ë¶€ì •í™•í•œ ì˜ˆì¸¡ TOP 10\n",
        "print(\"\\n[ê°€ì¥ ë¶€ì •í™•í•œ ì˜ˆì¸¡ TOP 10]\")\n",
        "worst_predictions = results_df.nlargest(10, 'abs_error')[\n",
        "    ['date', 'region', 'disease', 'actual', 'prediction', 'abs_error']\n",
        "]\n",
        "print(worst_predictions.to_string(index=False))\n",
        "\n",
        "# ============================================================\n",
        "# 9. í†µê³„ ìš”ì•½\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ“Š ì „ì²´ í†µê³„ ìš”ì•½\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ì´ ì˜ˆì¸¡ ê±´ìˆ˜: {len(results_df):,}ê±´\")\n",
        "print(f\"í‰ê·  ì‹¤ì œ í™•ì§„ì: {results_df['actual'].mean():.2f}ëª…\")\n",
        "print(f\"í‰ê·  ì˜ˆì¸¡ í™•ì§„ì: {results_df['prediction'].mean():.2f}ëª…\")\n",
        "print(f\"í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: {results_df['abs_error'].mean():.2f}ëª…\")\n",
        "print(f\"ì¤‘ì•™ê°’ ì ˆëŒ€ ì˜¤ì°¨: {results_df['abs_error'].median():.2f}ëª…\")\n",
        "print(f\"ìµœëŒ€ ì˜¤ì°¨: {results_df['abs_error'].max():.2f}ëª…\")\n",
        "print(f\"ìµœì†Œ ì˜¤ì°¨: {results_df['abs_error'].min():.2f}ëª…\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ============================================================\n",
        "# 10. CSV ì €ì¥ (ì„ íƒ)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥...\")\n",
        "\n",
        "# ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
        "# results_df.to_csv('lstm_dec2025_predictions.csv', index=False, encoding='utf-8-sig')\n",
        "# print(\"âœ… lstm_dec2025_predictions.csv ì €ì¥ ì™„ë£Œ!\")\n",
        "\n",
        "# ì§€ì—­ë³„ ìš”ì•½ ì €ì¥\n",
        "# region_total.to_csv('lstm_dec2025_region_summary.csv', encoding='utf-8-sig')\n",
        "# print(\"âœ… lstm_dec2025_region_summary.csv ì €ì¥ ì™„ë£Œ!\")\n",
        "\n",
        "# ì§ˆë³‘ë³„ ìš”ì•½ ì €ì¥\n",
        "# disease_total.to_csv('lstm_dec2025_disease_summary.csv', encoding='utf-8-sig')\n",
        "# print(\"âœ… lstm_dec2025_disease_summary.csv ì €ì¥ ì™„ë£Œ!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ‰ 2025ë…„ 12ì›” í™•ì§„ì ì˜ˆì¸¡ ë¶„ì„ ì™„ë£Œ!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(\"\\nğŸ’¡ ì¶”ê°€ ë¶„ì„ ë°©ë²•:\")\n",
        "print(\"  # íŠ¹ì • ì§€ì—­ë§Œ ë³´ê¸°\")\n",
        "print(\"  results_df[results_df['region']=='ì„œìš¸']\")\n",
        "print(\"\\n  # íŠ¹ì • ì§ˆë³‘ë§Œ ë³´ê¸°\")\n",
        "print(\"  results_df[results_df['disease']=='ë…ê°']\")\n",
        "print(\"\\n  # íŠ¹ì • ë‚ ì§œë§Œ ë³´ê¸°\")\n",
        "print(\"  results_df[results_df['date']=='2025-12-25']\")\n",
        "print(\"\\n  # ì˜¤ì°¨ê°€ í° ê²ƒë§Œ ë³´ê¸°\")\n",
        "print(\"  results_df[results_df['abs_error'] > 10]\")"
      ],
      "metadata": {
        "id": "CWX5NFmBADQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LZwJR36QAHMj"
      }
    }
  ]
}