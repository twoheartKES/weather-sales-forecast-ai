{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1g4asVNUVNocKhVdCos8XVM5YSFD4-5lg",
      "authorship_tag": "ABX9TyPQncbMcjcsNwyEz5aDY2LH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/twoheartKES/weather-sales-forecast-ai/blob/main/weather_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "610b1de5"
      },
      "source": [
        "# Task\n",
        "Process weekly disease data from CSV files for the years 2023, 2024, and 2025, and for specified regions (Seoul, Busan, Daegu, Incheon, Gwangju, Daejeon, Ulsan, Sejong, Gyeonggi, Gangwon, Chungbuk, Chungnam, Jeonbuk, Jeonnam, Gyeongbuk, Gyeongnam, Jeju) located in the directory `/content/drive/MyDrive/AI기상-질병데이터/`. For each file:\n",
        "1.  Load the weekly data into a pandas DataFrame.\n",
        "2.  Convert the weekly aggregated confirmed cases (from the `DATAARRTXT` column) into daily entries.\n",
        "3.  Filter the daily data based on specific date ranges for each year: '2023-01-01' to '2023-12-30' for 2023, '2023-12-31' to '2024-12-28' for 2024, and '2024-12-29' to '2025-12-27' for 2025.\n",
        "4.  Calculate evenly distributed daily confirmed cases by grouping by disease and week, summing weekly cases, and dividing by 7.\n",
        "5.  Construct a final DataFrame with columns 'date', 'disease_subtitle', 'disease_title', 'region', and 'confirmed_cases' (representing the evenly distributed daily cases).\n",
        "6.  Save the processed daily data to a new CSV file in the format `/content/drive/MyDrive/AI기상-질병데이터/{year}_지역별질병데이터_일별전처리_{region}.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e58a792"
      },
      "source": [
        "## Initialize Parameters and Date Ranges\n",
        "\n",
        "### Subtask:\n",
        "### 1. 파라미터 및 기간 설정\n",
        "- 분석 대상 연도(2023–2025)와 경기·서울 지역 코드 목록 정의\n",
        "- 연도별 일자 범위(date_ranges) 지정\n",
        "- 입력/출력용 Google Drive 경로 설정\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45017989"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define lists for years and regions, a dictionary for date ranges, and string variables for input/output directories as specified in the subtask instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7723286d",
        "outputId": "f4766852-7072-4c84-df1a-a39f831e3de8"
      },
      "source": [
        "years = [2023, 2024, 2025]\n",
        "regions = [\n",
        "    '경기_가평군_075',\n",
        "    '경기_고양시_덕양구_076',\n",
        "    '경기_고양시_일산동구_077',\n",
        "    '경기_고양시_일산서구_078',\n",
        "    '경기_과천시_079',\n",
        "    '경기_광명시_080',\n",
        "    '경기_광주시_081',\n",
        "    '경기_구리시_082',\n",
        "    '경기_군포시_083',\n",
        "    '경기_김포시_084',\n",
        "    '경기_남양주시_085',\n",
        "    '경기_동두천시_086',\n",
        "    '경기_부천시_130',\n",
        "    '경기_부천시_소사구_087',\n",
        "    '경기_부천시_오정구_088',\n",
        "    '경기_성남시_분당구_090',\n",
        "    '경기_성남시_수정구_091',\n",
        "    '경기_성남시_중원구_092',\n",
        "    '경기_수원시_권선구_093',\n",
        "    '경기_수원시_영통구_094',\n",
        "    '경기_수원시_장안구_095',\n",
        "    '경기_수원시_팔달구_096',\n",
        "    '경기_시흥시_097',\n",
        "    '경기_안산시_단원구_098',\n",
        "    '경기_안산시_상록구_099',\n",
        "    '경기_안성시_100',\n",
        "    '경기_안양시_동안구_101',\n",
        "    '경기_안양시_만안구_102',\n",
        "    '경기_양주시_103',\n",
        "    '경기_양평군_104',\n",
        "    '경기_여주시_105',\n",
        "    '경기_연천군_106',\n",
        "    '경기_오산시_107',\n",
        "    '경기_용인시_기흥구_108',\n",
        "    '경기_용인시_수지구_109',\n",
        "    '경기_용인시_처인구_110',\n",
        "    '경기_의왕시_111',\n",
        "    '경기_의정부시_112',\n",
        "    '경기_이천시_113',\n",
        "    '경기_파주시_114',\n",
        "    '경기_평택시_115',\n",
        "    '경기_포천시_116',\n",
        "    '경기_하남시_117',\n",
        "    '경기_화성시_118',\n",
        "    '서울_010',\n",
        "]\n",
        "\n",
        "date_ranges = {\n",
        "    2023: {'start_date': '2023-01-01', 'end_date': '2023-12-30'},\n",
        "    2024: {'start_date': '2023-12-31', 'end_date': '2024-12-28'},\n",
        "    2025: {'start_date': '2024-12-29', 'end_date': '2025-12-06'}\n",
        "}\n",
        "base_input_dir = '/content/drive/MyDrive/AI기상-질병데이터/'\n",
        "base_output_dir = '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/'\n",
        "\n",
        "print(\"Parameters and date ranges initialized successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters and date ranges initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1db3960d"
      },
      "source": [
        "## Process All Files in Loops\n",
        "\n",
        "### Subtask:\n",
        "각 연도와 지역을 순회하면서, 매 파일마다 주간 데이터를 불러오고 이를 일별 데이터로 변환한 뒤, 지정된 날짜 범위로 필터링하고, 주간 확진자 수를 일별로 균등 분배하여 최종 DataFrame을 구성하고 저장한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4bb9939"
      },
      "source": [
        "**Reasoning**:\n",
        "\n",
        "각 연도와 지역을 대상으로 중첩 반복문을 구현해, Subtask에서 제시한 상세 절차에 따라 파일을 처리해야 한다. 이 과정에는 주간 데이터 로딩, 일별 데이터로의 변환, 특정 날짜 범위 필터링, 일별 균등 분배 확진자 수 계산, 최종 DataFrame 생성 및 저장이 포함된다. 또한 파일 입출력 과정에서 오류에 대비해 try-except 블록을 함께 사용한다\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "date_ranges = {\n",
        "    2023: {'start_date': '2023-01-01', 'end_date': '2023-12-30'},\n",
        "    2024: {'start_date': '2023-12-31', 'end_date': '2024-12-28'},\n",
        "    2025: {'start_date': '2024-12-29', 'end_date': '2025-12-06'}\n",
        "}\n",
        "\n",
        "for year in years:\n",
        "    yearly_records = []  # ⭐ 연도별로 누적\n",
        "\n",
        "    for region in regions:\n",
        "        input_file_path = f\"{base_input_dir}{year}년확진자/kdca_{year}_week_{region}.csv\"\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(input_file_path, encoding='utf-8-sig')\n",
        "            print(f\"Loaded: {input_file_path}\")\n",
        "\n",
        "            # 연도 첫 일요일\n",
        "            year_start = pd.to_datetime(f\"{year}-01-01\")\n",
        "            first_sunday = year_start + pd.Timedelta(days=(6 - year_start.weekday()) % 7)\n",
        "\n",
        "            week_columns = [\n",
        "                col for col in df.columns\n",
        "                if col.startswith('COLUMN') and col != 'COLUMN1'\n",
        "            ]\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                disease_subtitle = row['SUBTITLE']\n",
        "\n",
        "                for week_idx, week_col in enumerate(week_columns):\n",
        "                    weekly_cases = row[week_col]\n",
        "\n",
        "                    if pd.isna(weekly_cases):\n",
        "                        weekly_cases = 0\n",
        "\n",
        "                    daily_cases = weekly_cases / 7\n",
        "                    week_start_date = first_sunday + pd.Timedelta(days=week_idx * 7)\n",
        "\n",
        "                    for day_offset in range(7):\n",
        "                        record_date = week_start_date + pd.Timedelta(days=day_offset)\n",
        "\n",
        "                        yearly_records.append({\n",
        "                            'date': record_date,\n",
        "                            'region': region,\n",
        "                            'disease_subtitle': disease_subtitle,\n",
        "                            'confirmed_cases': daily_cases\n",
        "                        })\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {input_file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {year} {region}: {e}\")\n",
        "\n",
        "    # ===============================\n",
        "    # 연도별 DataFrame 생성 & 필터\n",
        "    # ===============================\n",
        "    df_yearly = pd.DataFrame(yearly_records)\n",
        "\n",
        "    current_range = date_ranges[year]\n",
        "    df_yearly = df_yearly[\n",
        "        (df_yearly['date'] >= current_range['start_date']) &\n",
        "        (df_yearly['date'] <= current_range['end_date'])\n",
        "    ]\n",
        "\n",
        "    # 정렬 (분석용 필수)\n",
        "    df_yearly = df_yearly.sort_values(\n",
        "        by=['date', 'region', 'disease_subtitle']\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    # ===============================\n",
        "    # 저장\n",
        "    # ===============================\n",
        "    output_file_path = (\n",
        "        f\"{base_output_dir}{year}년_일별__지역별_확진자.csv\"\n",
        "    )\n",
        "\n",
        "    df_yearly.to_csv(output_file_path, index=False, encoding='utf-8')\n",
        "    print(f\"✅ Saved yearly file: {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNp3dsANQjhJ",
        "outputId": "61215580-1e20-4bdf-9a6f-188a5b110885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_가평군_075.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_고양시_덕양구_076.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_고양시_일산동구_077.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_고양시_일산서구_078.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_과천시_079.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_광명시_080.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_광주시_081.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_구리시_082.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_군포시_083.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_김포시_084.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_남양주시_085.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_동두천시_086.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_부천시_130.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_부천시_소사구_087.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_부천시_오정구_088.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_성남시_분당구_090.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_성남시_수정구_091.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_성남시_중원구_092.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_수원시_권선구_093.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_수원시_영통구_094.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_수원시_장안구_095.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_수원시_팔달구_096.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_시흥시_097.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_안산시_단원구_098.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_안산시_상록구_099.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_안성시_100.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_안양시_동안구_101.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_안양시_만안구_102.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_양주시_103.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_양평군_104.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_여주시_105.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_연천군_106.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_오산시_107.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_용인시_기흥구_108.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_용인시_수지구_109.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_용인시_처인구_110.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_의왕시_111.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_의정부시_112.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_이천시_113.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_파주시_114.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_평택시_115.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_포천시_116.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_하남시_117.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_경기_화성시_118.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2023년확진자/kdca_2023_week_서울_010.csv\n",
            "✅ Saved yearly file: /content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2023년_일별__지역별_확진자.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_가평군_075.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_고양시_덕양구_076.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_고양시_일산동구_077.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_고양시_일산서구_078.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_과천시_079.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_광명시_080.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_광주시_081.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_구리시_082.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_군포시_083.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_김포시_084.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_남양주시_085.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_동두천시_086.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_부천시_130.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_부천시_소사구_087.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_부천시_오정구_088.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_성남시_분당구_090.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_성남시_수정구_091.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_성남시_중원구_092.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_수원시_권선구_093.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_수원시_영통구_094.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_수원시_장안구_095.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_수원시_팔달구_096.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_시흥시_097.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_안산시_단원구_098.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_안산시_상록구_099.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_안성시_100.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_안양시_동안구_101.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_안양시_만안구_102.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_양주시_103.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_양평군_104.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_여주시_105.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_연천군_106.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_오산시_107.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_용인시_기흥구_108.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_용인시_수지구_109.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_용인시_처인구_110.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_의왕시_111.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_의정부시_112.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_이천시_113.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_파주시_114.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_평택시_115.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_포천시_116.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_하남시_117.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_경기_화성시_118.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2024년확진자/kdca_2024_week_서울_010.csv\n",
            "✅ Saved yearly file: /content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2024년_일별__지역별_확진자.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_가평군_075.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_고양시_덕양구_076.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_고양시_일산동구_077.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_고양시_일산서구_078.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_과천시_079.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_광명시_080.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_광주시_081.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_구리시_082.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_군포시_083.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_김포시_084.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_남양주시_085.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_동두천시_086.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_부천시_130.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_부천시_소사구_087.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_부천시_오정구_088.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_성남시_분당구_090.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_성남시_수정구_091.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_성남시_중원구_092.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_수원시_권선구_093.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_수원시_영통구_094.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_수원시_장안구_095.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_수원시_팔달구_096.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_시흥시_097.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_안산시_단원구_098.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_안산시_상록구_099.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_안성시_100.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_안양시_동안구_101.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_안양시_만안구_102.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_양주시_103.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_양평군_104.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_여주시_105.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_연천군_106.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_오산시_107.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_용인시_기흥구_108.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_용인시_수지구_109.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_용인시_처인구_110.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_의왕시_111.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_의정부시_112.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_이천시_113.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_파주시_114.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_평택시_115.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_포천시_116.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_하남시_117.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_경기_화성시_118.csv\n",
            "Loaded: /content/drive/MyDrive/AI기상-질병데이터/2025년확진자/kdca_2025_week_서울_010.csv\n",
            "✅ Saved yearly file: /content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2025년_일별__지역별_확진자.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ===============================\n",
        "# 1. 경로 설정\n",
        "# ===============================\n",
        "disease_dir = '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/'\n",
        "weather_dir = '/content/drive/MyDrive/AI기상-질병데이터/2023-2025기상데이터/'\n",
        "output_dir = '/content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 2. 날짜 범위 정의\n",
        "# ===============================\n",
        "date_ranges = {\n",
        "    2023: {'start_date': '2023-01-01', 'end_date': '2023-12-30'},\n",
        "    2024: {'start_date': '2023-12-31', 'end_date': '2024-12-28'},\n",
        "    2025: {'start_date': '2024-12-29', 'end_date': '2025-12-06'}\n",
        "}\n",
        "\n",
        "# ===============================\n",
        "# 3. 지역 → 지점명 매핑\n",
        "# ===============================\n",
        "mapping_regions = {\n",
        "    '동두천': [\n",
        "        '경기_구리시_082','경기_부천시_오정구_088','경기_과천시_079','경기_부천시_130',\n",
        "        '경기_광명시_080','경기_부천시_소사구_087','경기_고양시_덕양구_076',\n",
        "        '경기_의정부시_112','경기_고양시_일산동구_077','경기_고양시_일산서구_078',\n",
        "        '경기_하남시_117','경기_남양주시_085','경기_김포시_084','경기_양주시_103',\n",
        "        '경기_파주시_114','경기_동두천시_086',\n",
        "    ],\n",
        "    '수원': [\n",
        "        '경기_수원시_팔달구_096','경기_수원시_장안구_095','경기_수원시_권선구_093',\n",
        "        '경기_화성시_118','경기_수원시_영통구_094','경기_군포시_083',\n",
        "        '경기_용인시_기흥구_108','경기_의왕시_111','경기_성남시_수정구_091',\n",
        "        '경기_안산시_단원구_098','경기_성남시_중원구_092','경기_오산시_107',\n",
        "        '경기_안산시_상록구_099','경기_안양시_동안구_101','경기_용인시_수지구_109',\n",
        "        '경기_시흥시_097','경기_안양시_만안구_102','경기_성남시_분당구_090',\n",
        "        '경기_용인시_처인구_110','경기_평택시_115',\n",
        "    ],\n",
        "    '양평': ['경기_양평군_104','경기_광주시_081','경기_가평군_075'],\n",
        "    '이천': ['경기_이천시_113','경기_여주시_105','경기_안성시_100'],\n",
        "    '파주': ['경기_포천시_116','경기_연천군_106'],\n",
        "    '서울': ['서울_010'],\n",
        "}\n",
        "\n",
        "region_to_station = {\n",
        "    region: station\n",
        "    for station, regions in mapping_regions.items()\n",
        "    for region in regions\n",
        "}\n",
        "\n",
        "# ===============================\n",
        "# 4. 연도별 매핑 처리\n",
        "# ===============================\n",
        "for year in [2023, 2024, 2025]:\n",
        "\n",
        "    print(f\"\\n===== {year}년 처리 시작 =====\")\n",
        "\n",
        "\n",
        "    # 기상 데이터\n",
        "    weather_path = f\"{weather_dir}OBS_ASOS_DD_{year}.csv\"\n",
        "    df_weather = pd.read_csv(\n",
        "      weather_path,\n",
        "      encoding='cp949',\n",
        "      sep=','\n",
        "    )\n",
        "\n",
        "    df_weather['일시'] = pd.to_datetime(df_weather['일시'])\n",
        "\n",
        "    # 질병 데이터 (연도별 단일 파일)\n",
        "    disease_path = f\"{disease_dir}{year}년_일별__지역별_확진자.csv\"\n",
        "    df_disease = pd.read_csv(\n",
        "        disease_path,\n",
        "        encoding='utf-8-sig',\n",
        "        sep=','\n",
        "    )\n",
        "    print(\"질병컬럼\",df_disease.columns)\n",
        "    print(\"기상컬럼\",df_weather.columns)\n",
        "\n",
        "    assert df_disease['confirmed_cases'].isna().sum() == 0\n",
        "\n",
        "\n",
        "    df_disease['date'] = pd.to_datetime(df_disease['date'])\n",
        "\n",
        "\n",
        "\n",
        "    # 날짜 범위 컷\n",
        "    dr = date_ranges[year]\n",
        "    df_disease = df_disease[\n",
        "        (df_disease['date'] >= dr['start_date']) &\n",
        "        (df_disease['date'] <= dr['end_date'])\n",
        "    ]\n",
        "\n",
        "    # 지역 → 지점명 매핑\n",
        "    df_disease['지점명'] = df_disease['region'].map(region_to_station)\n",
        "    df_disease = df_disease.dropna(subset=['지점명'])\n",
        "\n",
        "    # 병합\n",
        "    df_merged = pd.merge(\n",
        "        df_disease,\n",
        "        df_weather,\n",
        "        left_on=['date', '지점명'],\n",
        "        right_on=['일시', '지점명'],\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # 정렬 (분석 안정성 확보)\n",
        "    df_merged = df_merged.sort_values(\n",
        "        by=['date', '지점명', 'disease_subtitle']\n",
        "    )\n",
        "\n",
        "    output_path = os.path.join(\n",
        "        output_dir,\n",
        "        f\"{year}년_일별_지역별_확진자_기상매핑.csv\"\n",
        "    )\n",
        "\n",
        "    df_merged.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"✅ 저장 완료: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoVF3K8aNPxM",
        "outputId": "2f2584e4-688e-4aad-b3c6-7ab8c6c047ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== 2023년 처리 시작 =====\n",
            "질병컬럼 Index(['date', 'region', 'disease_subtitle', 'confirmed_cases'], dtype='object')\n",
            "기상컬럼 Index(['지점', '지점명', '일시', '평균기온(°C)', '최저기온(°C)', '최저기온 시각(hhmi)', '최고기온(°C)',\n",
            "       '최고기온 시각(hhmi)', '강수 계속시간(hr)', '10분 최다 강수량(mm)', '10분 최다강수량 시각(hhmi)',\n",
            "       '1시간 최다강수량(mm)', '1시간 최다 강수량 시각(hhmi)', '일강수량(mm)', '최대 순간 풍속(m/s)',\n",
            "       '최대 순간 풍속 풍향(16방위)', '최대 순간풍속 시각(hhmi)', '최대 풍속(m/s)', '최대 풍속 풍향(16방위)',\n",
            "       '최대 풍속 시각(hhmi)', '평균 풍속(m/s)', '풍정합(100m)', '최다풍향(16방위)',\n",
            "       '평균 이슬점온도(°C)', '최소 상대습도(%)', '최소 상대습도 시각(hhmi)', '평균 상대습도(%)',\n",
            "       '평균 증기압(hPa)', '평균 현지기압(hPa)', '최고 해면기압(hPa)', '최고 해면기압 시각(hhmi)',\n",
            "       '최저 해면기압(hPa)', '최저 해면기압 시각(hhmi)', '평균 해면기압(hPa)', '가조시간(hr)',\n",
            "       '합계 일조시간(hr)', '1시간 최다일사 시각(hhmi)', '1시간 최다일사량(MJ/m2)', '합계 일사량(MJ/m2)',\n",
            "       '일 최심신적설(cm)', '일 최심신적설 시각(hhmi)', '일 최심적설(cm)', '일 최심적설 시각(hhmi)',\n",
            "       '합계 3시간 신적설(cm)', '평균 전운량(1/10)', '평균 중하층운량(1/10)', '평균 지면온도(°C)',\n",
            "       '최저 초상온도(°C)', '평균 5cm 지중온도(°C)', '평균 10cm 지중온도(°C)',\n",
            "       '평균 20cm 지중온도(°C)', '평균 30cm 지중온도(°C)', '0.5m 지중온도(°C)',\n",
            "       '1.0m 지중온도(°C)', '1.5m 지중온도(°C)', '3.0m 지중온도(°C)', '5.0m 지중온도(°C)',\n",
            "       '합계 대형증발량(mm)', '합계 소형증발량(mm)', '9-9강수(mm)', '기사', '안개 계속시간(hr)'],\n",
            "      dtype='object')\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2023년_일별_지역별_확진자_기상매핑.csv\n",
            "\n",
            "===== 2024년 처리 시작 =====\n",
            "질병컬럼 Index(['date', 'region', 'disease_subtitle', 'confirmed_cases'], dtype='object')\n",
            "기상컬럼 Index(['지점', '지점명', '일시', '평균기온(°C)', '최저기온(°C)', '최저기온 시각(hhmi)', '최고기온(°C)',\n",
            "       '최고기온 시각(hhmi)', '강수 계속시간(hr)', '10분 최다 강수량(mm)', '10분 최다강수량 시각(hhmi)',\n",
            "       '1시간 최다강수량(mm)', '1시간 최다 강수량 시각(hhmi)', '일강수량(mm)', '최대 순간 풍속(m/s)',\n",
            "       '최대 순간 풍속 풍향(16방위)', '최대 순간풍속 시각(hhmi)', '최대 풍속(m/s)', '최대 풍속 풍향(16방위)',\n",
            "       '최대 풍속 시각(hhmi)', '평균 풍속(m/s)', '풍정합(100m)', '최다풍향(16방위)',\n",
            "       '평균 이슬점온도(°C)', '최소 상대습도(%)', '최소 상대습도 시각(hhmi)', '평균 상대습도(%)',\n",
            "       '평균 증기압(hPa)', '평균 현지기압(hPa)', '최고 해면기압(hPa)', '최고 해면기압 시각(hhmi)',\n",
            "       '최저 해면기압(hPa)', '최저 해면기압 시각(hhmi)', '평균 해면기압(hPa)', '가조시간(hr)',\n",
            "       '합계 일조시간(hr)', '1시간 최다일사 시각(hhmi)', '1시간 최다일사량(MJ/m2)', '합계 일사량(MJ/m2)',\n",
            "       '일 최심신적설(cm)', '일 최심신적설 시각(hhmi)', '일 최심적설(cm)', '일 최심적설 시각(hhmi)',\n",
            "       '합계 3시간 신적설(cm)', '평균 전운량(1/10)', '평균 중하층운량(1/10)', '평균 지면온도(°C)',\n",
            "       '최저 초상온도(°C)', '평균 5cm 지중온도(°C)', '평균 10cm 지중온도(°C)',\n",
            "       '평균 20cm 지중온도(°C)', '평균 30cm 지중온도(°C)', '0.5m 지중온도(°C)',\n",
            "       '1.0m 지중온도(°C)', '1.5m 지중온도(°C)', '3.0m 지중온도(°C)', '5.0m 지중온도(°C)',\n",
            "       '합계 대형증발량(mm)', '합계 소형증발량(mm)', '9-9강수(mm)', '기사', '안개 계속시간(hr)'],\n",
            "      dtype='object')\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2024년_일별_지역별_확진자_기상매핑.csv\n",
            "\n",
            "===== 2025년 처리 시작 =====\n",
            "질병컬럼 Index(['date', 'region', 'disease_subtitle', 'confirmed_cases'], dtype='object')\n",
            "기상컬럼 Index(['지점', '지점명', '일시', '평균기온(°C)', '최저기온(°C)', '최저기온 시각(hhmi)', '최고기온(°C)',\n",
            "       '최고기온 시각(hhmi)', '강수 계속시간(hr)', '10분 최다 강수량(mm)', '10분 최다강수량 시각(hhmi)',\n",
            "       '1시간 최다강수량(mm)', '1시간 최다 강수량 시각(hhmi)', '일강수량(mm)', '최대 순간 풍속(m/s)',\n",
            "       '최대 순간 풍속 풍향(16방위)', '최대 순간풍속 시각(hhmi)', '최대 풍속(m/s)', '최대 풍속 풍향(16방위)',\n",
            "       '최대 풍속 시각(hhmi)', '평균 풍속(m/s)', '풍정합(100m)', '최다풍향(16방위)',\n",
            "       '평균 이슬점온도(°C)', '최소 상대습도(%)', '최소 상대습도 시각(hhmi)', '평균 상대습도(%)',\n",
            "       '평균 증기압(hPa)', '평균 현지기압(hPa)', '최고 해면기압(hPa)', '최고 해면기압 시각(hhmi)',\n",
            "       '최저 해면기압(hPa)', '최저 해면기압 시각(hhmi)', '평균 해면기압(hPa)', '가조시간(hr)',\n",
            "       '합계 일조시간(hr)', '1시간 최다일사 시각(hhmi)', '1시간 최다일사량(MJ/m2)', '합계 일사량(MJ/m2)',\n",
            "       '일 최심신적설(cm)', '일 최심신적설 시각(hhmi)', '일 최심적설(cm)', '일 최심적설 시각(hhmi)',\n",
            "       '합계 3시간 신적설(cm)', '평균 전운량(1/10)', '평균 중하층운량(1/10)', '평균 지면온도(°C)',\n",
            "       '최저 초상온도(°C)', '평균 5cm 지중온도(°C)', '평균 10cm 지중온도(°C)',\n",
            "       '평균 20cm 지중온도(°C)', '평균 30cm 지중온도(°C)', '0.5m 지중온도(°C)',\n",
            "       '1.0m 지중온도(°C)', '1.5m 지중온도(°C)', '3.0m 지중온도(°C)', '5.0m 지중온도(°C)',\n",
            "       '합계 대형증발량(mm)', '합계 소형증발량(mm)', '9-9강수(mm)', '기사', '안개 계속시간(hr)'],\n",
            "      dtype='object')\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2025년_일별_지역별_확진자_기상매핑.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21f2eaf2"
      },
      "source": [
        "## Summary:\n",
        "***\n",
        "\n",
        "#### Data Analysis Key Findings  \n",
        "- 파라미터 초기화 완료: 연도(2023, 2024, 2025), 지역(17개 지정 지역), 연도별 날짜 범위, 기본 디렉터리 경로 등 분석에 필요한 초기 설정은 정상적으로 완료되었다.  \n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfac2fe3"
      },
      "source": [
        "## Initialize Parameters for Consolidation\n",
        "\n",
        "### Subtask:\n",
        "실제 폴더/파일 구조 확인\n",
        "\n",
        "가장 우선적으로 /content/drive/MyDrive/AI기상-질병데이터/ 아래의 디렉터리 구조와 파일명을 직접 확인해야 한다.\n",
        "\n",
        "예:\n",
        "\n",
        "\"/content/drive/MyDrive/AI기상-질병데이터\"\n",
        "\n",
        "연도별 폴더 이름(예: 2023년확진자 vs 2023_년_확진자), 지역 문자열(경기_가평군_075), 파일 접미어 등 경로/이름이 코드와 정확히 일치하는지 점검이 필요하다.​\n",
        "\n",
        "파일 패턴 기반 자동 탐색 도입\n",
        "\n",
        "경로를 하드코딩하기보다, glob나 os.walk 등을 활용해 실제 존재하는 CSV 파일 목록을 먼저 읽어오고, 그 결과를 기준으로 연도·지역을 매핑하는 방식으로 개선할 수 있다.​\n",
        "\n",
        "예:\n",
        "\n",
        "glob(\"/content/drive/MyDrive/AI기상-질병데이터/**/*.csv\", recursive=True)\n",
        "\n",
        "이렇게 찾은 경로에서 year, region을 정규식 또는 split로 추출해, 코드의 years/regions와 싱크를 맞추는 방식."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb6ec2d3"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the lists for years and regions, and the base input and output directory paths as specified in the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "폐\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# ===============================\n",
        "# 1. 경로 설정\n",
        "# ===============================\n",
        "disease_dir = '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/'\n",
        "weather_dir = '/content/drive/MyDrive/AI기상-질병데이터/2023-2025기상데이터/'\n",
        "output_dir = '/content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 2. 지역 → 지점명 역매핑 생성\n",
        "# ===============================\n",
        "mapping_regions = {\n",
        "    '동두천': [\n",
        "        '경기_구리시_082','경기_부천시_오정구_088','경기_과천시_079','경기_부천시_130',\n",
        "        '경기_광명시_080','경기_부천시_소사구_087','경기_고양시_덕양구_076',\n",
        "        '경기_의정부시_112','경기_고양시_일산동구_077','경기_고양시_일산서구_078',\n",
        "        '경기_하남시_117','경기_남양주시_085','경기_김포시_084','경기_양주시_103',\n",
        "        '경기_파주시_114','경기_동두천시_086',\n",
        "    ],\n",
        "    '수원': [\n",
        "        '경기_수원시_팔달구_096','경기_수원시_장안구_095','경기_수원시_권선구_093',\n",
        "        '경기_화성시_118','경기_수원시_영통구_094','경기_군포시_083',\n",
        "        '경기_용인시_기흥구_108','경기_의왕시_111','경기_성남시_수정구_091',\n",
        "        '경기_안산시_단원구_098','경기_성남시_중원구_092','경기_오산시_107',\n",
        "        '경기_안산시_상록구_099','경기_안양시_동안구_101','경기_안양시_만안구_102',\n",
        "        '경기_성남시_분당구_090',\n",
        "        '경기_용인시_처인구_110','경기_평택시_115',\n",
        "    ],\n",
        "    '양평': ['경기_양평군_104','경기_광주시_081','경기_가평군_075'],\n",
        "    '이천': ['경기_이천시_113','경기_여주시_105','경기_안성시_100'],\n",
        "    '파주': ['경기_포천시_116','경기_연천군_106'],\n",
        "    '서울': ['서울_010'],\n",
        "}\n",
        "\n",
        "region_to_station = {\n",
        "    region: station\n",
        "    for station, regions in mapping_regions.items()\n",
        "    for region in regions\n",
        "}\n",
        "\n",
        "# ===============================\n",
        "# 3. 연도별 매핑 처리\n",
        "# ===============================\n",
        "for year in [2023, 2024, 2025]:\n",
        "\n",
        "    print(f\"\\n===== {year}년 처리 시작 =====\")\n",
        "\n",
        "    # 기상 데이터 로드\n",
        "    weather_path = f\"{weather_dir}OBS_ASOS_DD_{year}.csv\"\n",
        "    # Changed encoding to 'cp949' for potentially better Korean character handling\n",
        "    df_weather = pd.read_csv(weather_path, encoding='cp949')\n",
        "\n",
        "    df_weather['일시'] = pd.to_datetime(df_weather['일시'])\n",
        "\n",
        "    # 질병 데이터 파일 순회\n",
        "    for file in os.listdir(disease_dir):\n",
        "        if not file.startswith(str(year)):\n",
        "            continue\n",
        "\n",
        "        disease_path = os.path.join(disease_dir, file)\n",
        "        df_disease = pd.read_csv(disease_path, encoding='utf-8')\n",
        "\n",
        "        df_disease['date'] = pd.to_datetime(df_disease['date'])\n",
        "\n",
        "        # 지역 → 지점명 매핑\n",
        "        df_disease['지점명'] = df_disease['region'].map(region_to_station)\n",
        "\n",
        "        # 지점명이 없는 데이터 제거\n",
        "        df_disease = df_disease.dropna(subset=['지점명'])\n",
        "\n",
        "        # 날짜 + 지점명 기준 병합\n",
        "        df_merged = pd.merge(\n",
        "            df_disease,\n",
        "            df_weather,\n",
        "            left_on=['date', '지점명'],\n",
        "            right_on=['일시', '지점명'],\n",
        "            how='inner'\n",
        "        )\n",
        "\n",
        "        output_path = os.path.join(output_dir, file)\n",
        "        df_merged.to_csv(output_path, index=False, encoding='utf-8')\n",
        "\n",
        "        print(f\"매핑 완료: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "JHOSGnNqmoty",
        "outputId": "29f65944-14ab-4a77-b94e-d8a5e0e50268"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== 2023년 처리 시작 =====\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-309707512.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mdf_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"매핑 완료: {output_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                 )\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3965\u001b[0m         )\n\u001b[1;32m   3966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3967\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3968\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         )\n\u001b[0;32m-> 1014\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m             )\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_save_header\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_i\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslicer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_number_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         libwriters.write_csv_rows(\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mwriters.pyx\u001b[0m in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다시 새로운 마음으로 시작"
      ],
      "metadata": {
        "id": "o_fqqFB4YtPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 0. 기본 설정\n",
        "# ===============================\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "regions = [\n",
        "    '경기_가평군_075','경기_고양시_덕양구_076','경기_고양시_일산동구_077',\n",
        "    '경기_고양시_일산서구_078','경기_과천시_079','경기_광명시_080',\n",
        "    '경기_광주시_081','경기_구리시_082','경기_군포시_083','경기_김포시_084',\n",
        "    '경기_남양주시_085','경기_동두천시_086','경기_부천시_130',\n",
        "    '경기_부천시_소사구_087','경기_부천시_오정구_088',\n",
        "    '경기_성남시_분당구_090','경기_성남시_수정구_091','경기_성남시_중원구_092',\n",
        "    '경기_수원시_권선구_093','경기_수원시_영통구_094',\n",
        "    '경기_수원시_장안구_095','경기_수원시_팔달구_096',\n",
        "    '경기_시흥시_097','경기_안산시_단원구_098','경기_안산시_상록구_099',\n",
        "    '경기_안성시_100','경기_안양시_동안구_101','경기_안양시_만안구_102',\n",
        "    '경기_양주시_103','경기_양평군_104','경기_여주시_105',\n",
        "    '경기_연천군_106','경기_오산시_107',\n",
        "    '경기_용인시_기흥구_108','경기_용인시_수지구_109','경기_용인시_처인구_110',\n",
        "    '경기_의왕시_111','경기_의정부시_112','경기_이천시_113',\n",
        "    '경기_파주시_114','경기_평택시_115','경기_포천시_116',\n",
        "    '경기_하남시_117','경기_화성시_118','서울_010'\n",
        "]\n",
        "\n",
        "date_ranges = {\n",
        "    2023: {'start_date': '2023-01-01', 'end_date': '2023-12-30'},\n",
        "    2024: {'start_date': '2023-12-31', 'end_date': '2024-12-28'},\n",
        "    2025: {'start_date': '2024-12-29', 'end_date': '2025-12-06'}\n",
        "}\n",
        "\n",
        "base_input_dir = '/content/drive/MyDrive/AI기상-질병데이터/'\n",
        "base_output_dir = '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/'\n",
        "\n",
        "# ===============================\n",
        "# 1. 연도별 처리\n",
        "# ===============================\n",
        "for year in years:\n",
        "    yearly_records = []\n",
        "\n",
        "    for region in regions:\n",
        "        input_path = f\"{base_input_dir}{year}년확진자/kdca_{year}_week_{region}.csv\"\n",
        "\n",
        "        try:\n",
        "            df = pd.read_csv(input_path, encoding='utf-8-sig')\n",
        "\n",
        "            year_start = pd.to_datetime(f\"{year}-01-01\")\n",
        "            first_sunday = year_start + pd.Timedelta(days=(6 - year_start.weekday()) % 7)\n",
        "\n",
        "            week_columns = [\n",
        "                col for col in df.columns\n",
        "                if col.startswith('COLUMN') and col != 'COLUMN1'\n",
        "            ]\n",
        "\n",
        "            for _, row in df.iterrows():\n",
        "                disease = row['SUBTITLE']\n",
        "\n",
        "                for week_idx, week_col in enumerate(week_columns):\n",
        "                    weekly_cases = row[week_col]\n",
        "                    if pd.isna(weekly_cases):\n",
        "                        weekly_cases = 0\n",
        "\n",
        "                    daily_cases = weekly_cases / 7\n",
        "                    week_start = first_sunday + pd.Timedelta(days=week_idx * 7)\n",
        "\n",
        "                    for d in range(7):\n",
        "                        yearly_records.append({\n",
        "                            'date': week_start + pd.Timedelta(days=d),\n",
        "                            'region': region,\n",
        "                            'disease_subtitle': disease,\n",
        "                            'confirmed_cases': daily_cases\n",
        "                        })\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            print(f\"❌ 파일 없음: {input_path}\")\n",
        "\n",
        "    df_year = pd.DataFrame(yearly_records)\n",
        "\n",
        "    dr = date_ranges[year]\n",
        "    df_year = df_year[\n",
        "        (df_year['date'] >= dr['start_date']) &\n",
        "        (df_year['date'] <= dr['end_date'])\n",
        "    ]\n",
        "\n",
        "    df_year = df_year.sort_values(\n",
        "        ['date', 'region', 'disease_subtitle']\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    output_path = f\"{base_output_dir}{year}년_일별_지역별_확진자.csv\"\n",
        "\n",
        "    # 🔴 인코딩 통일 (중요)\n",
        "    df_year.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"✅ 저장 완료: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxUb9WvhYwP3",
        "outputId": "4eeae365-3bfe-4673-fb07-ee98898182b8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2023년_일별_지역별_확진자.csv\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2024년_일별_지역별_확진자.csv\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2025년_일별_지역별_확진자.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "disease_dir = '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/'\n",
        "weather_dir = '/content/drive/MyDrive/AI기상-질병데이터/2023-2025기상데이터/'\n",
        "output_dir = '/content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/'\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "date_ranges = {\n",
        "    2023: {'start_date': '2023-01-01', 'end_date': '2023-12-30'},\n",
        "    2024: {'start_date': '2023-12-31', 'end_date': '2024-12-28'},\n",
        "    2025: {'start_date': '2024-12-29', 'end_date': '2025-12-06'}\n",
        "}\n",
        "\n",
        "mapping_regions = {\n",
        "    '동두천': [\n",
        "        '경기_구리시_082','경기_부천시_오정구_088','경기_과천시_079',\n",
        "        '경기_부천시_130','경기_광명시_080','경기_부천시_소사구_087',\n",
        "        '경기_고양시_덕양구_076','경기_의정부시_112',\n",
        "        '경기_고양시_일산동구_077','경기_고양시_일산서구_078',\n",
        "        '경기_하남시_117','경기_남양주시_085','경기_김포시_084',\n",
        "        '경기_양주시_103','경기_파주시_114','경기_동두천시_086'\n",
        "    ],\n",
        "    '수원': [\n",
        "        '경기_수원시_팔달구_096','경기_수원시_장안구_095',\n",
        "        '경기_수원시_권선구_093','경기_화성시_118',\n",
        "        '경기_수원시_영통구_094','경기_군포시_083',\n",
        "        '경기_용인시_기흥구_108','경기_의왕시_111',\n",
        "        '경기_성남시_수정구_091','경기_안산시_단원구_098',\n",
        "        '경기_성남시_중원구_092','경기_오산시_107',\n",
        "        '경기_안산시_상록구_099','경기_안양시_동안구_101',\n",
        "        '경기_용인시_수지구_109','경기_시흥시_097',\n",
        "        '경기_안양시_만안구_102','경기_성남시_분당구_090',\n",
        "        '경기_용인시_처인구_110','경기_평택시_115'\n",
        "    ],\n",
        "    '양평': ['경기_양평군_104','경기_광주시_081','경기_가평군_075'],\n",
        "    '이천': ['경기_이천시_113','경기_여주시_105','경기_안성시_100'],\n",
        "    '파주': ['경기_포천시_116','경기_연천군_106'],\n",
        "    '서울': ['서울_010']\n",
        "}\n",
        "\n",
        "region_to_station = {\n",
        "    r: s for s, rs in mapping_regions.items() for r in rs\n",
        "}\n",
        "\n",
        "for year in [2023, 2024, 2025]:\n",
        "    print(f\"\\n===== {year}년 매핑 =====\")\n",
        "\n",
        "    df_weather = pd.read_csv(\n",
        "        f\"{weather_dir}OBS_ASOS_DD_{year}.csv\",\n",
        "        encoding='cp949'\n",
        "    )\n",
        "    df_weather['일시'] = pd.to_datetime(df_weather['일시'])\n",
        "\n",
        "    df_disease = pd.read_csv(\n",
        "        f\"{disease_dir}{year}년_일별_지역별_확진자.csv\",\n",
        "        encoding='utf-8-sig'\n",
        "    )\n",
        "    df_disease['date'] = pd.to_datetime(df_disease['date'])\n",
        "\n",
        "    dr = date_ranges[year]\n",
        "    df_disease = df_disease[\n",
        "        (df_disease['date'] >= dr['start_date']) &\n",
        "        (df_disease['date'] <= dr['end_date'])\n",
        "    ]\n",
        "\n",
        "    df_disease['지점명'] = df_disease['region'].map(region_to_station)\n",
        "    df_disease = df_disease.dropna(subset=['지점명'])\n",
        "\n",
        "    df_merge = pd.merge(\n",
        "        df_disease,\n",
        "        df_weather,\n",
        "        left_on=['date', '지점명'],\n",
        "        right_on=['일시', '지점명'],\n",
        "        how='inner'\n",
        "    ).sort_values(['date', '지점명', 'disease_subtitle'])\n",
        "\n",
        "    output_path = f\"{output_dir}{year}년_일별_지역별_확진자_기상매핑.csv\"\n",
        "    df_merge.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(f\"✅ 저장 완료: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bf4lHJaY_5m",
        "outputId": "d7292864-c7fb-4561-fc76-395cd7691cad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== 2023년 매핑 =====\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2023년_일별_지역별_확진자_기상매핑.csv\n",
            "\n",
            "===== 2024년 매핑 =====\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2024년_일별_지역별_확진자_기상매핑.csv\n",
            "\n",
            "===== 2025년 매핑 =====\n",
            "✅ 저장 완료: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2025년_일별_지역별_확진자_기상매핑.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "climate_numeric_cols = [\n",
        "'평균기온(°C)',\n",
        "'최저기온(°C)',\n",
        "'최고기온(°C)',\n",
        "'평균 이슬점온도(°C)',\n",
        "'평균 상대습도(%)',\n",
        "'최소 상대습도(%)',\n",
        "'평균 증기압(hPa)',\n",
        "'일강수량(mm)',\n",
        "'강수 계속시간(hr)',\n",
        "'1시간 최다강수량(mm)',\n",
        "'평균 풍속(m/s)',\n",
        "'최대 순간 풍속(m/s)',\n",
        "'합계 일조시간(hr)',\n",
        "'합계 일사량(MJ/m2)',\n",
        "'평균 지면온도(°C)',\n",
        "'안개 계속시간(hr)',\n",
        "]"
      ],
      "metadata": {
        "id": "XAWn8QQpchTe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 1. 데이터 로드 gpt\n",
        "# ===============================\n",
        "base_output_dir = '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/'\n",
        "\n",
        "\n",
        "input_path = f\"{base_output_dir}{year}년_일별_지역별_확진자_기상매핑.csv\"\n",
        "\n",
        "df = pd.read_csv(\n",
        "    input_path,\n",
        "    encoding='utf-8-sig'\n",
        ")\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# ===============================\n",
        "# 2. 기후 수치형 컬럼 정의\n",
        "# ===============================\n",
        "climate_numeric_cols = [\n",
        "    '평균기온(°C)','최저기온(°C)','최고기온(°C)',\n",
        "    '평균 이슬점온도(°C)','평균 상대습도(%)','최소 상대습도(%)',\n",
        "    '평균 증기압(hPa)','일강수량(mm)','강수 계속시간(hr)',\n",
        "    '1시간 최다강수량(mm)','평균 풍속(m/s)','최대 순간 풍속(m/s)',\n",
        "    '합계 일조시간(hr)','합계 일사량(MJ/m2)',\n",
        "    '평균 지면온도(°C)','안개 계속시간(hr)'\n",
        "]\n",
        "\n",
        "# ===============================\n",
        "# 3. 타입 정제 (필수)\n",
        "# ===============================\n",
        "for col in climate_numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# ===============================\n",
        "# 4. 정렬 (시계열 feature 필수 조건)\n",
        "# ===============================\n",
        "df = df.sort_values(\n",
        "    by=['지점명', 'date']\n",
        ").reset_index(drop=True)\n",
        "\n",
        "# ===============================\n",
        "# 5. 결측치 처리 (확정 전략)\n",
        "# ===============================\n",
        "# 지점별 시계열 기준 선형 보간\n",
        "df[climate_numeric_cols] = (\n",
        "    df.groupby('지점명')[climate_numeric_cols]\n",
        "      .apply(lambda x: x.interpolate(method='linear'))\n",
        ")\n",
        "\n",
        "# ===============================\n",
        "# 6. Lag Feature 생성\n",
        "# ===============================\n",
        "lag_days = [1, 3, 7, 14]\n",
        "\n",
        "for lag in lag_days:\n",
        "    for col in climate_numeric_cols:\n",
        "        df[f'{col}_lag{lag}'] = (\n",
        "            df.groupby('지점명')[col].shift(lag)\n",
        "        )\n",
        "\n",
        "# ===============================\n",
        "# 7. Rolling Feature 생성\n",
        "# ===============================\n",
        "rolling_windows = [3, 7, 14]\n",
        "\n",
        "for window in rolling_windows:\n",
        "    for col in climate_numeric_cols:\n",
        "        df[f'{col}_roll{window}'] = (\n",
        "            df.groupby('지점명')[col]\n",
        "              .rolling(window)\n",
        "              .mean()\n",
        "              .reset_index(level=0, drop=True)\n",
        "        )\n",
        "\n",
        "# ===============================\n",
        "# 8. 결측치 최종 정리\n",
        "# ===============================\n",
        "df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "# ===============================\n",
        "# 9. 저장\n",
        "# ===============================\n",
        "output_path = '2023년_feature_engineered_dataset.csv'\n",
        "\n",
        "df.to_csv(\n",
        "    output_path,\n",
        "    index=False,\n",
        "    encoding='utf-8-sig'\n",
        ")\n",
        "\n",
        "print(f\"✅ Feature Engineering 완료: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "pk3pPdrFfKMG",
        "outputId": "4f37377e-d8b9-4467-99d3-ea07b67becfd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2023년_일별_지역별_확진자_기상매핑.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-874274881.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{base_output_dir}{year}년_일별_지역별_확진자_기상매핑.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m df = pd.read_csv(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/AI기상-질병데이터/질병데이터 일별로 전처리/2023년_일별_지역별_확진자_기상매핑.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk3pdrFfKMG",
        "outputId": "0a6eea5f-e48f-40a0-ecfe-3e3f525c2614"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define output_dir to load from and save to\n",
        "output_dir = '/content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/'\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "# ===============================\n",
        "# 2. 기후 수치형 컬럼 정의\n",
        "# ===============================\n",
        "climate_numeric_cols = [\n",
        "    '평균기온(°C)','최저기온(°C)','최고기온(°C)',\n",
        "    '평균 이슬점온도(°C)','평균 상대습도(%)','최소 상대습도(%)',\n",
        "    '평균 증기압(hPa)','일강수량(mm)','강수 계속시간(hr)',\n",
        "    '1시간 최다강수량(mm)','평균 풍속(m/s)','최대 순간 풍속(m/s)',\n",
        "    '합계 일조시간(hr)','합계 일사량(MJ/m2)',\n",
        "    '평균 지면온도(°C)','안개 계속시간(hr)'\n",
        "]\n",
        "\n",
        "for year in years:\n",
        "    print(f\"\\n===== {year}년 Feature Engineering 시작 =====\")\n",
        "\n",
        "    # ===============================\n",
        "    # 1. 데이터 로드 (매핑된 데이터)\n",
        "    # ===============================\n",
        "    input_path = f\"{output_dir}{year}년_일별_지역별_확진자_기상매핑.csv\"\n",
        "\n",
        "    df = pd.read_csv(\n",
        "        input_path,\n",
        "        encoding='utf-8-sig'\n",
        "    )\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    # ===============================\n",
        "    # 3. 타입 정제 (필수)\n",
        "    # ===============================\n",
        "    for col in climate_numeric_cols:\n",
        "        # Check if the column exists before trying to convert\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        else:\n",
        "            print(f\"Warning: Column '{col}' not found in DataFrame for {year}.\")\n",
        "\n",
        "    # ===============================\n",
        "    # 4. 정렬 (시계열 feature 필수 조건)\n",
        "    # ===============================\n",
        "    df = df.sort_values(\n",
        "        by=['지점명', 'date']\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    # ===============================\n",
        "    # 5. 결측치 처리 (확정 전략)\n",
        "    # ===============================\n",
        "    # 지점별 시계열 기준 선형 보간\n",
        "    # Filter to only existing climate numeric columns before applying interpolation\n",
        "    existing_climate_cols = [col for col in climate_numeric_cols if col in df.columns]\n",
        "    if existing_climate_cols:\n",
        "        # Changed .apply(lambda x: x.interpolate(method='linear')) to .transform(lambda x: x.interpolate(method='linear'))\n",
        "        df[existing_climate_cols] = (\n",
        "            df.groupby('지점명')[existing_climate_cols]\n",
        "              .transform(lambda x: x.interpolate(method='linear'))\n",
        "        )\n",
        "    else:\n",
        "        print(f\"No existing climate numeric columns to interpolate for {year}.\")\n",
        "\n",
        "\n",
        "    # ===============================\n",
        "    # 6. Lag Feature 생성\n",
        "    # ===============================\n",
        "    lag_days = [1, 3, 7, 14]\n",
        "\n",
        "    for lag in lag_days:\n",
        "        for col in existing_climate_cols:\n",
        "            df[f'{col}_lag{lag}'] = (\n",
        "                df.groupby('지점명')[col].shift(lag)\n",
        "            )\n",
        "\n",
        "    # ===============================\n",
        "    # 7. Rolling Feature 생성\n",
        "    # ===============================\n",
        "    rolling_windows = [3, 7, 14]\n",
        "\n",
        "    for window in rolling_windows:\n",
        "        for col in existing_climate_cols:\n",
        "            df[f'{col}_roll{window}'] = (\n",
        "                df.groupby('지점명')[col]\n",
        "                  .rolling(window)\n",
        "                  .mean()\n",
        "                  .reset_index(level=0, drop=True)\n",
        "            )\n",
        "\n",
        "    # ===============================\n",
        "    # 8. 결측치 최종 정리\n",
        "    # ===============================\n",
        "    # Drop rows with NaN values created by shift/rolling operations\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    # ===============================\n",
        "    # 9. 저장\n",
        "# ===============================\n",
        "    output_file_path = f\"{output_dir}{year}년_feature_engineered_dataset.csv\"\n",
        "\n",
        "    df.to_csv(\n",
        "        output_file_path,\n",
        "        index=False,\n",
        "        encoding='utf-8-sig'\n",
        "    )\n",
        "\n",
        "    print(f\"✅ Feature Engineering 완료 및 저장: {output_file_path}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== 2023년 Feature Engineering 시작 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature Engineering 완료 및 저장: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2023년_feature_engineered_dataset.csv\n",
            "\n",
            "===== 2024년 Feature Engineering 시작 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature Engineering 완료 및 저장: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2024년_feature_engineered_dataset.csv\n",
            "\n",
            "===== 2025년 Feature Engineering 시작 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n",
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Feature Engineering 완료 및 저장: /content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/2025년_feature_engineered_dataset.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1421773537.py:90: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[f'{col}_roll{window}'] = (\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# 0. 기본 설정\n",
        "# ===============================\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "input_dir = '/content/drive/MyDrive/AI기상-질병데이터/년도별 매핑 데이터/'\n",
        "output_dir = '/content/drive/MyDrive/AI기상-질병데이터/feature_dataset/'\n",
        "\n",
        "import os\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# 1. 기후 수치형 컬럼\n",
        "# ===============================\n",
        "climate_numeric_cols = [\n",
        "    '평균기온(°C)','최저기온(°C)','최고기온(°C)',\n",
        "    '평균 이슬점온도(°C)','평균 상대습도(%)','최소 상대습도(%)',\n",
        "    '평균 증기압(hPa)','일강수량(mm)','강수 계속시간(hr)',\n",
        "    '1시간 최다강수량(mm)','평균 풍속(m/s)','최대 순간 풍속(m/s)',\n",
        "    '합계 일조시간(hr)','합계 일사량(MJ/m2)',\n",
        "    '평균 지면온도(°C)','안개 계속시간(hr)'\n",
        "]\n",
        "\n",
        "# ===============================\n",
        "# 2. 연도별 반복 처리\n",
        "# ===============================\n",
        "for year in years:\n",
        "    print(f\"\\n===== {year}년 Feature Engineering 시작 ====\")\n",
        "\n",
        "    input_path = f\"{input_dir}{year}년_일별_지역별_확진자_기상매핑.csv\"\n",
        "\n",
        "    df = pd.read_csv(\n",
        "        input_path,\n",
        "        encoding='utf-8-sig'\n",
        "    )\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    print(\"▶ DataFrame shape:\", df.shape)\n",
        "    print(\"▶ Columns (앞 10개):\")\n",
        "    print(df.columns.tolist()[:10])\n",
        "    print(\"▶ Index type:\", type(df.index))\n",
        "\n",
        "\n",
        "    # -------------------------------\n",
        "    # 컬럼 존재 여부 검증 (안전장치)\n",
        "    # -------------------------------\n",
        "    missing_cols = [c for c in climate_numeric_cols if c not in df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"{year}년 데이터에 기후 컬럼 없음: {missing_cols}\")\n",
        "\n",
        "    print(\"\\n[CHECK] climate_numeric_cols 존재 여부\")\n",
        "\n",
        "    missing_cols = [c for c in climate_numeric_cols if c not in df.columns]\n",
        "\n",
        "    if missing_cols:\n",
        "        print(\"❌ 존재하지 않는 컬럼:\")\n",
        "        for c in missing_cols:\n",
        "            print(\"   -\", repr(c))\n",
        "    else:\n",
        "        print(\"✅ 모든 climate 컬럼 존재\")\n",
        "\n",
        "\n",
        "    # -------------------------------\n",
        "    # 타입 정제\n",
        "    # -------------------------------\n",
        "\n",
        "    print(\"\\n[CHECK] climate 컬럼 dtype\")\n",
        "\n",
        "    print(df[climate_numeric_cols].dtypes)\n",
        "\n",
        "    for col in climate_numeric_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # -------------------------------\n",
        "    # 정렬 (지점별 시계열) - interpolate 전에 정렬 필수\n",
        "    # -------------------------------\n",
        "    df = df.sort_values(\n",
        "        by=['지점명', 'date']\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    # -------------------------------\n",
        "    # 결측치 처리 (지점별 선형 보간)\n",
        "    # -------------------------------\n",
        "    df[climate_numeric_cols] = (\n",
        "    df.groupby('지점명')[climate_numeric_cols]\n",
        "      .transform(lambda x: x.interpolate(method='linear'))\n",
        "    )\n",
        "\n",
        "    tmp = (\n",
        "        df.groupby('지점명')[climate_numeric_cols]\n",
        "          .transform(lambda x: x.interpolate(method='linear'))\n",
        "    )\n",
        "\n",
        "    print(\"\\n[CHECK] interpolate 결과\")\n",
        "    print(\" - type:\", type(tmp))\n",
        "    print(\" - shape:\", tmp.shape)\n",
        "    print(\" - index equals df.index ?\", tmp.index.equals(df.index))\n",
        "\n",
        "\n",
        "    # -------------------------------\n",
        "    # Lag Feature\n",
        "    # -------------------------------\n",
        "    lag_days = [1, 3, 7, 14]\n",
        "    lag_features = [] # List to store new lag features\n",
        "\n",
        "    for lag in lag_days:\n",
        "        for col in climate_numeric_cols:\n",
        "            lag_features.append(\n",
        "                df.groupby('지점명')[col].shift(lag).rename(f'{col}_lag{lag}')\n",
        "            )\n",
        "\n",
        "    # Concatenate all lag features at once\n",
        "    if lag_features:\n",
        "        df = pd.concat([df] + lag_features, axis=1)\n",
        "\n",
        "    col = climate_numeric_cols[0]\n",
        "\n",
        "    tmp_lag = (\n",
        "        df.groupby('지점명')[col]\n",
        "          .transform(lambda x: x.shift(1))\n",
        "    )\n",
        "\n",
        "    print(\"\\n[CHECK] lag feature\")\n",
        "    print(\" - type:\", type(tmp_lag))\n",
        "    print(\" - length:\", len(tmp_lag))\n",
        "    print(\" - index equals df.index ?\", tmp_lag.index.equals(df.index))\n",
        "\n",
        "    # -------------------------------\n",
        "    # Rolling Feature\n",
        "    # -------------------------------\n",
        "    rolling_windows = [3, 7, 14]\n",
        "    rolling_features = [] # List to store new rolling features\n",
        "\n",
        "    for window in rolling_windows:\n",
        "        for col in climate_numeric_cols:\n",
        "            rolling_features.append(\n",
        "                df.groupby('지점명')[col]\n",
        "                  .rolling(window)\n",
        "                  .mean()\n",
        "                  .reset_index(level=0, drop=True)\n",
        "                  .rename(f'{col}_roll{window}')\n",
        "            )\n",
        "\n",
        "    # Concatenate all rolling features at once\n",
        "    if rolling_features:\n",
        "        df = pd.concat([df] + rolling_features, axis=1)\n",
        "\n",
        "    # -------------------------------\n",
        "    # 결측 제거\n",
        "    # -------------------------------\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "\n",
        "    tmp_roll = (\n",
        "        df.groupby('지점명')[col]\n",
        "          .transform(lambda x: x.rolling(7).mean())\n",
        "    )\n",
        "\n",
        "    print(\"\\n[CHECK] rolling feature\")\n",
        "    print(\" - type:\", type(tmp_roll))\n",
        "    print(\" - length:\", len(tmp_roll))\n",
        "    print(\" - index equals df.index ?\", tmp_roll.index.equals(df.index))\n",
        "\n",
        "    # -------------------------------\n",
        "    # 저장\n",
        "    # -------------------------------\n",
        "    output_path = f\"{output_dir}{year}년_feature_engineered_dataset.csv\"\n",
        "\n",
        "    df.to_csv(\n",
        "        output_path,\n",
        "        index=False,\n",
        "        encoding='utf-8-sig'\n",
        "    )\n",
        "\n",
        "    print(f\"✅ {year}년 Feature Engineering 완료\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7JoSPCajjd2",
        "outputId": "868c95a0-b9f4-4c5f-e565-5437958c8974"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== 2023년 Feature Engineering 시작 ====\n",
            "▶ DataFrame shape: (212940, 66)\n",
            "▶ Columns (앞 10개):\n",
            "['date', 'region', 'disease_subtitle', 'confirmed_cases', '지점명', '지점', '일시', '평균기온(°C)', '최저기온(°C)', '최저기온 시각(hhmi)']\n",
            "▶ Index type: <class 'pandas.core.indexes.range.RangeIndex'>\n",
            "\n",
            "[CHECK] climate_numeric_cols 존재 여부\n",
            "✅ 모든 climate 컬럼 존재\n",
            "\n",
            "[CHECK] climate 컬럼 dtype\n",
            "평균기온(°C)         float64\n",
            "최저기온(°C)         float64\n",
            "최고기온(°C)         float64\n",
            "평균 이슬점온도(°C)     float64\n",
            "평균 상대습도(%)       float64\n",
            "최소 상대습도(%)       float64\n",
            "평균 증기압(hPa)      float64\n",
            "일강수량(mm)         float64\n",
            "강수 계속시간(hr)      float64\n",
            "1시간 최다강수량(mm)    float64\n",
            "평균 풍속(m/s)       float64\n",
            "최대 순간 풍속(m/s)    float64\n",
            "합계 일조시간(hr)      float64\n",
            "합계 일사량(MJ/m2)    float64\n",
            "평균 지면온도(°C)      float64\n",
            "안개 계속시간(hr)      float64\n",
            "dtype: object\n",
            "\n",
            "[CHECK] interpolate 결과\n",
            " - type: <class 'pandas.core.frame.DataFrame'>\n",
            " - shape: (212940, 16)\n",
            " - index equals df.index ? True\n",
            "\n",
            "[CHECK] lag feature\n",
            " - type: <class 'pandas.core.series.Series'>\n",
            " - length: 212940\n",
            " - index equals df.index ? True\n",
            "\n",
            "[CHECK] rolling feature\n",
            " - type: <class 'pandas.core.series.Series'>\n",
            " - length: 0\n",
            " - index equals df.index ? True\n",
            "✅ 2023년 Feature Engineering 완료\n",
            "\n",
            "===== 2024년 Feature Engineering 시작 ====\n",
            "▶ DataFrame shape: (208845, 66)\n",
            "▶ Columns (앞 10개):\n",
            "['date', 'region', 'disease_subtitle', 'confirmed_cases', '지점명', '지점', '일시', '평균기온(°C)', '최저기온(°C)', '최저기온 시각(hhmi)']\n",
            "▶ Index type: <class 'pandas.core.indexes.range.RangeIndex'>\n",
            "\n",
            "[CHECK] climate_numeric_cols 존재 여부\n",
            "✅ 모든 climate 컬럼 존재\n",
            "\n",
            "[CHECK] climate 컬럼 dtype\n",
            "평균기온(°C)         float64\n",
            "최저기온(°C)         float64\n",
            "최고기온(°C)         float64\n",
            "평균 이슬점온도(°C)     float64\n",
            "평균 상대습도(%)       float64\n",
            "최소 상대습도(%)       float64\n",
            "평균 증기압(hPa)      float64\n",
            "일강수량(mm)         float64\n",
            "강수 계속시간(hr)      float64\n",
            "1시간 최다강수량(mm)    float64\n",
            "평균 풍속(m/s)       float64\n",
            "최대 순간 풍속(m/s)    float64\n",
            "합계 일조시간(hr)      float64\n",
            "합계 일사량(MJ/m2)    float64\n",
            "평균 지면온도(°C)      float64\n",
            "안개 계속시간(hr)      float64\n",
            "dtype: object\n",
            "\n",
            "[CHECK] interpolate 결과\n",
            " - type: <class 'pandas.core.frame.DataFrame'>\n",
            " - shape: (208845, 16)\n",
            " - index equals df.index ? True\n",
            "\n",
            "[CHECK] lag feature\n",
            " - type: <class 'pandas.core.series.Series'>\n",
            " - length: 208845\n",
            " - index equals df.index ? True\n",
            "\n",
            "[CHECK] rolling feature\n",
            " - type: <class 'pandas.core.series.Series'>\n",
            " - length: 0\n",
            " - index equals df.index ? True\n",
            "✅ 2024년 Feature Engineering 완료\n",
            "\n",
            "===== 2025년 Feature Engineering 시작 ====\n",
            "▶ DataFrame shape: (196560, 66)\n",
            "▶ Columns (앞 10개):\n",
            "['date', 'region', 'disease_subtitle', 'confirmed_cases', '지점명', '지점', '일시', '평균기온(°C)', '최저기온(°C)', '최저기온 시각(hhmi)']\n",
            "▶ Index type: <class 'pandas.core.indexes.range.RangeIndex'>\n",
            "\n",
            "[CHECK] climate_numeric_cols 존재 여부\n",
            "✅ 모든 climate 컬럼 존재\n",
            "\n",
            "[CHECK] climate 컬럼 dtype\n",
            "평균기온(°C)         float64\n",
            "최저기온(°C)         float64\n",
            "최고기온(°C)         float64\n",
            "평균 이슬점온도(°C)     float64\n",
            "평균 상대습도(%)       float64\n",
            "최소 상대습도(%)         int64\n",
            "평균 증기압(hPa)      float64\n",
            "일강수량(mm)         float64\n",
            "강수 계속시간(hr)      float64\n",
            "1시간 최다강수량(mm)    float64\n",
            "평균 풍속(m/s)       float64\n",
            "최대 순간 풍속(m/s)    float64\n",
            "합계 일조시간(hr)      float64\n",
            "합계 일사량(MJ/m2)    float64\n",
            "평균 지면온도(°C)      float64\n",
            "안개 계속시간(hr)      float64\n",
            "dtype: object\n",
            "\n",
            "[CHECK] interpolate 결과\n",
            " - type: <class 'pandas.core.frame.DataFrame'>\n",
            " - shape: (196560, 16)\n",
            " - index equals df.index ? True\n",
            "\n",
            "[CHECK] lag feature\n",
            " - type: <class 'pandas.core.series.Series'>\n",
            " - length: 196560\n",
            " - index equals df.index ? True\n",
            "\n",
            "[CHECK] rolling feature\n",
            " - type: <class 'pandas.core.series.Series'>\n",
            " - length: 260\n",
            " - index equals df.index ? True\n",
            "✅ 2025년 Feature Engineering 완료\n"
          ]
        }
      ]
    }
  ]
}